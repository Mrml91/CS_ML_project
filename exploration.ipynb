{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "from kaggle_submit import submit_to_kaggle\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICTURES_FOLDER = \"pictures\"\n",
    "os.makedirs(PICTURES_FOLDER, exist_ok=True)\n",
    "\n",
    "SLEEP_STAGES_COLORS = {\n",
    "    0: \"blue\",\n",
    "    1: \"green\",     \n",
    "    2: \"red\",\n",
    "    3: \"black\",\n",
    "    4: \"orange\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = 'kaggle_data/X_train.h5/X_train.h5', errno = 17, error message = 'File exists', flags = 15, o_flags = a02)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to lock file, errno = 35, error message = 'Resource temporarily unavailable')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-08493fbbb047>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"kaggle_data/X_test.h5/X_test.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mh5_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mh5_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                                swmr=swmr)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         warn(\"The default file mode will change to 'r' (read-only) in h5py 3.0. \"\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = 'kaggle_data/X_train.h5/X_train.h5', errno = 17, error message = 'File exists', flags = 15, o_flags = a02)"
     ]
    }
   ],
   "source": [
    "train_file = \"kaggle_data/X_train.h5/X_train.h5\"\n",
    "test_file = \"kaggle_data/X_test.h5/X_test.h5\"\n",
    "\n",
    "h5_train = h5py.File(train_file, mode='a')\n",
    "h5_test = h5py.File(test_file, mode='a')\n",
    "\n",
    "y_train = pd.read_csv(\"kaggle_data/y_train.csv\", index_col=0, squeeze=True)\n",
    "y_train_arr = y_train.to_numpy()\n",
    "\n",
    "# MAKE FEATURES\n",
    "from additional_features.make_features import make_all_features\n",
    "make_all_features(h5_train,h5_test,overwrite=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES (sorted) = ['accel_norm', 'accel_norm_ft_logmod', 'alpha_eeg_1_logE', 'alpha_eeg_2_logE', 'alpha_eeg_3_logE', 'alpha_eeg_4_logE', 'alpha_eeg_5_logE', 'alpha_eeg_6_logE', 'alpha_eeg_7_logE', 'beta_eeg_1_logE', 'beta_eeg_2_logE', 'beta_eeg_3_logE', 'beta_eeg_4_logE', 'beta_eeg_5_logE', 'beta_eeg_6_logE', 'beta_eeg_7_logE', 'delta_eeg_1_logE', 'delta_eeg_2_logE', 'delta_eeg_3_logE', 'delta_eeg_4_logE', 'delta_eeg_5_logE', 'delta_eeg_6_logE', 'delta_eeg_7_logE', 'eeg_1', 'eeg_1_ft_logmod', 'eeg_2', 'eeg_2_ft_logmod', 'eeg_3', 'eeg_3_ft_logmod', 'eeg_4', 'eeg_4_ft_logmod', 'eeg_5', 'eeg_5_ft_logmod', 'eeg_6', 'eeg_6_ft_logmod', 'eeg_7', 'eeg_7_ft_logmod', 'pulse', 'pulse_ft_logmod', 'pulse_max_freq', 'pulse_max_logE', 'sleep_left', 'sleep_time', 'sleep_time_relative', 'speed_norm', 'speed_norm_ft_logmod', 'theta_eeg_1_logE', 'theta_eeg_2_logE', 'theta_eeg_3_logE', 'theta_eeg_4_logE', 'theta_eeg_5_logE', 'theta_eeg_6_logE', 'theta_eeg_7_logE']\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "IRRELEVANT_FEATURES = ['index', 'index_absolute', 'index_window',\n",
    "                       'x', 'y', 'z',\n",
    "                       'speed_x', 'speed_y', 'speed_z',\n",
    "                       #'eeg_1', 'eeg_2','eeg_3','eeg_4','eeg_5', 'eeg_6', 'eeg_7',\n",
    "                       #'pulse',\n",
    "                      ]\n",
    "\n",
    "def update_globals():\n",
    "    features = [feat for feat in h5_train.keys() if feat not in IRRELEVANT_FEATURES]\n",
    "    frequencies = {feat: h5_train[feat][0].size // 30 for feat in features}\n",
    "    frequencies = {feat: freq if int(freq) in (10, 50) else 0 \n",
    "                   for feat, freq in frequencies.items()}\n",
    "    return features, frequencies\n",
    "    \n",
    "FEATURES, FREQUENCIES = update_globals()\n",
    "print(\"FEATURES (sorted) =\", sorted(FEATURES))\n",
    "# print(\"FREQUENCIES =\", FREQUENCIES)\n",
    "print(len(FEATURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from additional_features.make_features import make_all_features\n",
    "\n",
    "make_all_features(h5_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES, FREQUENCIES = update_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62\u001b[1K\r"
     ]
    }
   ],
   "source": [
    "#def ensure_integrity(h5_file):\n",
    "#    keys = list(h5_file.keys())\n",
    "#    for i, key in enumerate(keys):\n",
    "#        print_bis(f'{i+1}/{len(keys)}')\n",
    "#        x = h5_file[key][:]\n",
    "#        assert np.sum(np.isnan(x)) == 0\n",
    "#        assert np.sum(np.isinf(x)) == 0\n",
    "        \n",
    "#ensure_integrity(h5_train)\n",
    "#ensure_integrity(h5_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def robust_rescale(df):\n",
    "    \"\"\"\n",
    "    X_rescaled = (X - MED(X)) / MED(|X - MED(X)|)\n",
    "    \"\"\"\n",
    "    med = df.median()\n",
    "    med_spread = (df - df.median()).abs().median()\n",
    "    # df_rescaled = (df - med) / med_spread\n",
    "    return (df - med) / med_spread\n",
    "\n",
    "def min_max_rescale(df):\n",
    "    min_ = df.min()\n",
    "    max_ = df.max()\n",
    "    return (df - min_) / (max_ - min_)\n",
    "    \n",
    "def z_rescale(df): \n",
    "    mean = df.mean()\n",
    "    std = df.std()\n",
    "    return (df - mean) / std\n",
    "\n",
    "def get_fig_subjects():\n",
    "    fig, axes = plt.subplots(10, 3, figsize=(10, 40))\n",
    "    return fig, np.ravel(axes)\n",
    "\n",
    "def title_with_subject_id(ax, subject_id):\n",
    "    ax.set_title(f'SUBJECT #{subject_id}')\n",
    "    return None\n",
    "\n",
    "def save_feature_quantiles(feature,\n",
    "                           inf_qt=0.025,\n",
    "                           sup_qt=0.975,\n",
    "                           n_quantiles=21,\n",
    "                           robust_rescaling=False,\n",
    "                           overwrite=False,\n",
    "                           verbose=True):\n",
    "    \"\"\"\n",
    "    See pictures/quantile_plots\n",
    "    \n",
    "    Can be improved (make robust and not robust qplots simultaneously)\n",
    "    \"\"\"\n",
    "    # Make directory if it does not exist\n",
    "    qplot_dir = os.path.join(PICTURES_FOLDER, f\"quantile_plots\")\n",
    "    os.makedirs(qplot_dir, exist_ok=True)\n",
    "    # Escape if not overwrite and already done\n",
    "    qplot_fname = os.path.join(qplot_dir, f'{feature}{\"--rescaled\" if robust_rescaling else \"\"}.png')\n",
    "    if (not overwrite) and os.path.exists(qplot_fname):\n",
    "        return None\n",
    "    # Otherwise,\n",
    "    subject_ids = get_subject_ids(h5_train)\n",
    "    quantiles = np.linspace(inf_qt, sup_qt, n_quantiles).round(3)\n",
    "    subjects_quantiles = dict()\n",
    "    for cnt, sid in enumerate(subject_ids):\n",
    "        if verbose:\n",
    "            print_bis(f\"FEATURE #{FEATURES.index(feature)} SUBJECT {cnt+1}/{len(subject_ids)} (RESCALE = {str(robust_rescaling)})\")\n",
    "        # Robust representation of the signal\n",
    "        signal = get_subject_feature_signals(h5_train, sid, feature, frequencies_dict=FREQUENCIES, as_timeseries=False)\n",
    "        size = signal[0].size\n",
    "        signal = pd.Series(np.concatenate(signal))\n",
    "        if robust_rescaling:\n",
    "            signal = robust_rescale(signal)\n",
    "        # Behaviour by sleep stage\n",
    "        sleep_stages = get_subject_sleep_stage(sid, h5_train, y_train).values\n",
    "        signal_by_stage = signal.groupby(np.repeat(sleep_stages, size))\n",
    "        subjects_quantiles[sid] = signal_by_stage.quantile(quantiles).unstack(0)\n",
    "        \n",
    "    fig, axes = get_fig_subjects()\n",
    "    for ax, sid in zip(axes, subject_ids):\n",
    "        subjects_quantiles[sid].plot(ax=ax)#, color=SLEEP_STAGES_COLORS)\n",
    "        title_with_subject_id(ax, sid)\n",
    "    plt.savefig(qplot_fname)\n",
    "    plt.close(fig)\n",
    "    return subjects_quantiles\n",
    "\n",
    "\n",
    "# TO WRITE QUANTILE PLOTS IN pictures/quantile_plots\n",
    "#for i, feat in enumerate(FEATURES):\n",
    "    # print_ter(f\"========= FEATURE {i+1}/{len(FEATURES)} =========\")\n",
    "#    save_feature_quantiles(feat, robust_rescaling=False, overwrite=False, verbose=True)\n",
    "#    save_feature_quantiles(feat, robust_rescaling=True, overwrite=False, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_proba_transition(subject_id=None):\n",
    "    if subject_id:\n",
    "        start, end = get_subject_boundaries(h5_train, subject_id, ready_to_use=False)\n",
    "        y = y_train.loc[start:end]\n",
    "    else: # all subjects\n",
    "        y = y_train.loc[:]\n",
    "    transition_df = pd.DataFrame(data={\"stage\": y, \"stage_after\": y.shift(-1)})\n",
    "    transition_df = transition_df.iloc[:-1] # NaN\n",
    "    transition_df = transition_df.astype(int)\n",
    "    counts = transition_df.groupby([\"stage\", \"stage_after\"]).size()\n",
    "    counts = counts.unstack(1, fill_value=0)\n",
    "    probas = counts.div(counts.sum(axis=1), axis=0)\n",
    "    probas = probas.reindex(range(0, 5), axis=0, fill_value=0)\n",
    "    probas = probas.reindex(range(0, 5), axis=1, fill_value=0)\n",
    "    return probas\n",
    "\n",
    "transition_plots_dir = os.path.join(PICTURES_FOLDER, \"transition_plots\")\n",
    "os.makedirs(transition_plots_dir, exist_ok=True)\n",
    "\n",
    "def save_transition_plots_by_subject(overwrite=False, verbose=True):\n",
    "    fpath = os.path.join(transition_plots_dir, \"transition_matrix_by_subject.png\")\n",
    "    if (not overwrite) and os.path.exists(fpath):\n",
    "        return None\n",
    "    subject_ids = get_subject_ids(h5_train)\n",
    "    fig, axes = get_fig_subjects()\n",
    "    for ax, sid in zip(axes, subject_ids):\n",
    "        if verbose:\n",
    "            print_bis(f\"SUBJECT #{sid}\")\n",
    "        probas = get_proba_transition(subject_id=sid)\n",
    "        sns.heatmap(probas, ax=ax, vmin=0, vmax=1, annot=True)\n",
    "        title_with_subject_id(ax, sid)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(fpath)\n",
    "    plt.close(fig)    \n",
    "    return None\n",
    "\n",
    "def save_transition_plot_global(overwrite=False):\n",
    "    fpath = os.path.join(transition_plots_dir, \"transition_matrix_global.png\")\n",
    "    if (not overwrite) and os.path.exists(fpath):\n",
    "        return None\n",
    "    proba_global = get_proba_transition()\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(proba_global, ax=ax, vmin=0, vmax=1, annot=True)\n",
    "    fig.savefig(fpath)\n",
    "    plt.close(fig)\n",
    "    return None\n",
    "    \n",
    "save_transition_plots_by_subject(overwrite=False)\n",
    "save_transition_plot_global(overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_energies = [feature for feature, freq in FREQUENCIES.items() if freq == 0]\n",
    "log_energies_df = pd.DataFrame({le: h5_train[le][:][:, 0] for le in log_energies})\n",
    "sns.heatmap(log_energies_df.corr(), center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3511\n",
       "1    1671\n",
       "2    9449\n",
       "3    5224\n",
       "4    4833\n",
       "Name: sleep_stage, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_stages_frequencies = y_train.groupby(y_train.values).count()\n",
    "sleep_stages_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features are of 3 kinds\n",
    "\n",
    "TIME_FEATURES = ['accel_norm', 'eeg_1', 'eeg_2', 'eeg_3', 'eeg_4', 'eeg_5', 'eeg_6', 'eeg_7', 'pulse', 'speed_norm']\n",
    "SPECTRAL_FEATURES = [f\"{time_feat}_ft_logmod\" for time_feat in TIME_FEATURES]\n",
    "MONO_FEATURES = [feat for feat in FEATURES if h5_train[feat][0].shape[0] == 1]\n",
    "\n",
    "assert set(MONO_FEATURES).union(set(TIME_FEATURES)).union(set(SPECTRAL_FEATURES)) ==  set(FEATURES) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantiles \n",
    "\n",
    "LOWER_TAIL_QUANTILES = [0.01, 0.025, 0.05]\n",
    "DECILES = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "UPPER_TAIL_QUANTILES = [0.95, 0.975, 0.99]\n",
    "\n",
    "QUANTILES = LOWER_TAIL_QUANTILES + DECILES + UPPER_TAIL_QUANTILES\n",
    "TAIL_QUANTILES = LOWER_TAIL_QUANTILES + UPPER_TAIL_QUANTILES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to create input array\n",
    "\n",
    "# See pywavelets [https://pywavelets.readthedocs.io/en/latest/] for wavelet transform\n",
    "\n",
    "# Extreme values of features have been used --> extreme quantiles are a good idea\n",
    "\n",
    "# It is said in the study that there is a need for large samples to have correct resolution in frequency\n",
    "#    ---> make chunks of 30s windows ??\n",
    "\n",
    "\n",
    "def get_distribution_quantiles(arr, quantiles, **kwargs):\n",
    "    return np.quantile(arr, q=quantiles, axis=1, **kwargs).T\n",
    "\n",
    "\n",
    "def get_distribution_characteristics(arr, truncate_dist=False):\n",
    "    \"\"\"\n",
    "    mean, variance, skewness, kurtosis\n",
    "    \"\"\"\n",
    "    if truncate_dist:\n",
    "        inf = get_distribution_quantiles(arr, 0.005, keepdims=True)\n",
    "        sup = get_distribution_quantiles(arr, 0.995, keepdims=True)\n",
    "        return get_distribution_quantiles(np.clip(arr, inf, sup), truncate_dist=False)\n",
    "    res = np.empty(shape=(arr.shape[0], 4))\n",
    "    res[:, 0] = np.mean(arr, axis=1, keepdims=False) # mean [order 1]\n",
    "    res[:, 1] = np.mean((arr - res[:, [0]]) ** 2, axis=1, keepdims=False) # variance [order 2]\n",
    "    z_var = ( arr - res[:, [0]] ) / res[:, [1]] \n",
    "    res[:, 2] = np.mean(z_var ** 3, axis=1, keepdims=False) # skewness [order 3]\n",
    "    res[:, 3] = np.mean(z_var ** 4, axis=1, keepdims=False) # kurtosis [order 4]\n",
    "    return res\n",
    "\n",
    "\n",
    "def _make_input_multidimensional_feature_chunk(sequences, quantiles=QUANTILES, dist_char=True, truncate_dist=False):\n",
    "    n_samples = sequences.shape[0]\n",
    "    n_cols = len(quantiles) * int(len(quantiles) > 0) + 4 * int(dist_char)\n",
    "    assert n_cols > 0\n",
    "    res = np.empty(shape=(n_samples, n_cols))\n",
    "    res[:, :len(quantiles)] = get_distribution_quantiles(sequences, quantiles)\n",
    "    if dist_char:\n",
    "        res[:, -4:] = get_distribution_characteristics(sequences, truncate_dist=truncate_dist)\n",
    "    return res\n",
    "        \n",
    "\n",
    "def make_input_multidimensional_feature(h5_file, \n",
    "                                        feature, \n",
    "                                        quantiles=QUANTILES, \n",
    "                                        dist_char=True,\n",
    "                                        truncate_dist=False,\n",
    "                                        n_chunks=100):\n",
    "    n_cols = len(quantiles) * int(len(quantiles) > 0) + 4 * int(dist_char)\n",
    "    feature_array = np.empty(shape=(h5_file[feature].shape[0], n_cols))\n",
    "    columns = [(feature, str(q)) for q in quantiles] + [(feature, mom) for mom in range(1,5) if dist_char]\n",
    "    \n",
    "    for i, j in chunks_iterator(n_chunks, h5_file[feature].shape[0]):\n",
    "        feature_array[i:j, :] = _make_input_multidimensional_feature_chunk(\n",
    "            h5_file[feature][i:j], quantiles, dist_char, truncate_dist)\n",
    "        \n",
    "    return feature_array, columns\n",
    "\n",
    "\n",
    "### Rescaling\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "# already robust on not logE features because we take quantiles\n",
    "# --> StandardScaler \n",
    "\n",
    "def make_input(h5_file, features=FEATURES, quantiles=QUANTILES, dist_char=True, truncate_dist=False, rescale=True):\n",
    "    n_mono = sum([feat in MONO_FEATURES for feat in features])\n",
    "    n_cols_multi = len(quantiles) + 4 * int(dist_char)\n",
    "    n_cols = n_mono + n_cols_multi * (len(features) - n_mono)\n",
    "    input_arr = np.empty(shape=(h5_file[\"index\"].shape[0], n_cols))\n",
    "    i = 0\n",
    "    columns = list()\n",
    "    for cnt, feat in enumerate(features):\n",
    "        print_bis(f\"Feature #{cnt}/{len(features)}\")\n",
    "        if feat in MONO_FEATURES:\n",
    "            input_arr[:, [i]] = h5_file[feat][:]\n",
    "            columns = columns + [(feat, \"\")]\n",
    "            i += 1\n",
    "        else:\n",
    "            input_arr[:, i:i+n_cols_multi], cols = make_input_multidimensional_feature(\n",
    "                h5_file, feat, quantiles, dist_char, truncate_dist)\n",
    "            columns = columns + cols\n",
    "            i += n_cols_multi\n",
    "    if rescale:\n",
    "        ids = get_subject_ids(h5_file)\n",
    "        for id in ids:\n",
    "            indices = subjects_ids_to_indexers(h5_file, [id], as_indices=True, as_boolean_array=False)\n",
    "            z_scaler = StandardScaler()\n",
    "            input_arr[indices,:] = z_scaler.fit_transform(input_arr[indices,:])            \n",
    "    return pd.DataFrame(input_arr, columns=pd.MultiIndex.from_tuples(columns))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT TRAIN / CROSS VALIDATION\n",
    "\n",
    "def split_train_validation_subject_ids(train_perc, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    subjects_ids = get_subject_ids(h5_train)\n",
    "    shuffled_ids = np.random.permutation(subjects_ids)\n",
    "    N_train = int(np.round(train_perc * len(shuffled_ids)))\n",
    "    train_ids, validation_ids = shuffled_ids[:N_train], shuffled_ids[N_train:]\n",
    "    return sorted(train_ids), sorted(validation_ids)\n",
    "\n",
    "def subjects_ids_to_indexers(h5_file, subjects_ids, as_indices=False, as_boolean_array=False):\n",
    "    if as_indices == as_boolean_array:\n",
    "        raise NameError('Choose between `indices` and `boolean array` representations')\n",
    "    if as_indices:\n",
    "        boundaries = [get_subject_boundaries(h5_file, sid, ready_to_use=False) for sid in subjects_ids]\n",
    "        return sum(map(lambda bounds: list(range(bounds[0], bounds[1]+1)), boundaries), list())\n",
    "    if as_boolean_array:\n",
    "        boolean_indexer = np.zeros(shape=(h5_file[FEATURES[0]].shape[0],), dtype=bool)\n",
    "        for sid in subjects_ids:\n",
    "            boolean_indexer[get_subject_boundaries(h5_file, sid, ready_to_use=True)] = True\n",
    "        return boolean_indexer\n",
    "        \n",
    "    \n",
    "def split_train_validation(X_train, \n",
    "                           train_subjects_ids=None, # ids for train\n",
    "                           train_perc=None,\n",
    "                           seed=None):\n",
    "    if (train_subjects_ids is None) and (train_perc is None):\n",
    "        raise NameError(\"Either `subjects_ids` or `train_perc` must be provided\")\n",
    "    if train_perc is not None:\n",
    "        train_subjects_ids, _ = split_train_validation_subject_ids(train_perc, seed)\n",
    "        return split_train_validation(X_train, train_subjects_ids=train_subjects_ids)\n",
    "    \n",
    "    train_selector = subjects_ids_to_indexers(h5_train, train_subjects_ids, as_boolean_array=True)\n",
    "    X_train_train, y_train_train = X_train[train_selector], y_train.values[train_selector]\n",
    "    X_train_val, y_train_val = X_train[~train_selector], y_train.values[~train_selector]\n",
    "    \n",
    "    return X_train_train, y_train_train, X_train_val, y_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def get_eta_repr(elapsed, iteration, total_iterations):\n",
    "    if iteration == 0:\n",
    "        return \"?\"\n",
    "    else:\n",
    "        eta = (elapsed / iteration) * (total_iterations - iteration)\n",
    "        return str(np.round(eta, 2)) + \"s\"\n",
    "    \n",
    "    \n",
    "def train_on_grid(model_blueprint, params_grid, X, y):\n",
    "    # Random shuffling of parameters for better ETA\n",
    "    shuffled_ix = np.random.permutation(range(len(params_grid))) # for better ETA\n",
    "    \n",
    "    models = [None for _ in range(len(params_grid))] \n",
    "    elapsed_time = 0\n",
    "    time_start = time.time()\n",
    "\n",
    "    for i, ix in enumerate(shuffled_ix):\n",
    "        print_bis(f\"Training Model #{i+1}/{len(params_grid)} \" +\\\n",
    "                  f\"[ETA: {get_eta_repr(time.time() - time_start, i, len(params_grid))}]\")\n",
    "        model = model_blueprint(**params_grid[ix])\n",
    "        model.fit(X, y)\n",
    "                \n",
    "        models[ix] = model\n",
    "        \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def custom_score(y_pred, y_true):\n",
    "    return fbeta_score(y_pred=y_pred,\n",
    "                       y_true=y_true,\n",
    "                       labels=[0, 1, 2, 3, 4],\n",
    "                       average=\"weighted\",\n",
    "                       beta=1)\n",
    "\n",
    "def get_models_custom_scoring(models, X_train_train, y_train_train, X_train_val, y_train_val):\n",
    "    scores = list()\n",
    "    time_start = time.time()\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        eta = get_eta_repr(time.time() - time_start, i, len(models))\n",
    "        print_bis(f\"Scoring Model #{i+1}/{len(models)} [ETA: {eta}]\")\n",
    "        \n",
    "        y_train_pred = model.predict(X_train_train)\n",
    "        y_val_pred = model.predict(X_train_val)\n",
    "        model_scores = {\n",
    "            \"training_score\": custom_score(y_train_pred, y_train_train),\n",
    "            \"validation_score\": custom_score(y_val_pred, y_train_val),\n",
    "        }\n",
    "        \n",
    "        \n",
    "        scores.append(model_scores)\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(models, models_params, models_scores, criterion=\"validation_score\"):\n",
    "    ix_best_score = np.argmax([s[criterion] for s in models_scores])\n",
    "    best_model = models[ix_best_score]\n",
    "    best_model_params = models_params[ix_best_score]\n",
    "    best_model_score = models_scores[ix_best_score]\n",
    "    return best_model, best_model_params, best_model_score\n",
    "\n",
    "def sort_models(models, models_params, models_scores, criterion=\"validation_score\"):\n",
    "    return sorted(zip(models, models_params, models_scores), key=lambda x: x[2][criterion])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE MODEL\n",
    "\n",
    "from joblib import dump, load\n",
    "ARCHIVES_FOLDER = \"models_archives\"\n",
    "if not os.path.exists(ARCHIVES_FOLDER):\n",
    "    os.makedirs(ARCHIVES_FOLDER)\n",
    "\n",
    "def save_model(model, name):\n",
    "    fpath = os.path.join(ARCHIVES_FOLDER, f\"{name}.joblib\")\n",
    "    dump(model, fpath)\n",
    "    print(f\"New model saved at {fpath}\")\n",
    "    return fpath\n",
    "    \n",
    "    \n",
    "def load_model(name):\n",
    "    if not name.startswith(ARCHIVES_FOLDER):\n",
    "        name = os.path.join(ARCHIVES_FOLDER, name)\n",
    "    if not name.endswith(\".joblib\"):\n",
    "        name = f\"{name}.joblib\"\n",
    "    model = load(name)\n",
    "    return model\n",
    "\n",
    "LEADERBOARD_FILE = \"leaderboard.txt\"\n",
    "if not os.path.exists(LEADERBOARD_FILE):\n",
    "    with open(LEADERBOARD_FILE, 'a') as leaderboard:\n",
    "        leaderboard.write(\";;;\".join(['path', 'training_score', 'validation_score', 'comments']))\n",
    "    \n",
    "def write_model_to_leaderboard(model, model_name, train_score, val_score, comments=\"\"):\n",
    "    fpath = save_model(model, model_name)\n",
    "    with open(LEADERBOARD_FILE, \"a\") as leaderboard:\n",
    "        leaderboard.write(\"\\n\" + ';;;'.join([fpath, str(train_score), str(val_score), comments]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this later : sklearn.model_selection.HalvingRandomSearchCV\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def get_inputs(make_input_func, scaler, seed=None):\n",
    "    X_train = make_input_func(h5_train)\n",
    "    X_test = make_input_func(h5_test)\n",
    "\n",
    "    train_ids, validation_ids = split_train_validation_subject_ids(0.7, seed=seed)\n",
    "    X_train_train, y_train_train, X_train_val, y_train_val = split_train_validation(\n",
    "        X_train, train_subjects_ids=train_ids)\n",
    "\n",
    "\n",
    "    X_train_train = scaler.fit_transform(X_train_train)\n",
    "    X_train_val = scaler.transform(X_train_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_train, y_train_train, X_train_val, y_train_val, X_test\n",
    "\n",
    "\n",
    "def train_until_convergence(models, X, y, verbose=True):\n",
    "    time_start = time.time()\n",
    "    for i, model in enumerate(models):\n",
    "        print_bis(f\"TRAINING UNTIL CONVERGENCE : MODEL #{i+1}/{len(models)} [ETA: {get_eta_repr(time.time() - time_start, i, len(models))}\")\n",
    "        model.set_params(max_iter=-1)\n",
    "        model.fit(X, y)\n",
    "    return models\n",
    "        \n",
    "\n",
    "def svm_no_PCA_selector( ## A REFAIRE AVEC LA DEUXIEME SELECTION SUR UN AUTRE SET QUE LA CROSS VALIDATION\n",
    "    make_input_func,\n",
    "    scaler,\n",
    "    params_grid,\n",
    "    name,\n",
    "    comments=\"\",\n",
    "    select=3,\n",
    "    max_iter=1000,\n",
    "    seed=None):\n",
    "    \n",
    "    params_grid_bounded = [{k: v for k, v in pg.items()} for pg in params_grid]\n",
    "    for d in params_grid_bounded:\n",
    "        d[\"max_iter\"] = max_iter\n",
    "    \n",
    "    X_train_train, y_train_train, X_train_val, y_train_val, X_test = \\\n",
    "        get_inputs_svm(make_input_func, scaler, seed=seed)\n",
    "   \n",
    "\n",
    "    # Hyperparameters space exploration\n",
    "\n",
    "    # Training\n",
    "    print(\"-------- (PRE-)TRAINING --------\")\n",
    "    svm_models = train_on_grid(SVC, params_grid_bounded, X_train_train, y_train_train)\n",
    "\n",
    "    # Scoring\n",
    "    print_ter(\"-------- CROSS-VALIDATION --------\")\n",
    "    svm_scores = get_models_custom_scoring(svm_models, X_train_train, y_train_train, X_train_val, y_train_val)\n",
    "\n",
    "    # Pre-Selecting\n",
    "    print_ter(\"-------- SELECTION --------\")\n",
    "    sorted_models = sort_models(svm_models, params_grid_bounded, svm_scores, criterion=\"validation_score\")\n",
    "    candidates = sorted_models[-select:]\n",
    "    candidates = [model for model, params, score in candidates]\n",
    "    \n",
    "    # Train until convergence\n",
    "    print_ter(\"-------- TRAINING CANDIDATES UNTIL CONVERGENCE --------\")\n",
    "    candidates_at_cvg = train_until_convergence(candidates, X_train_train, y_train_train)\n",
    "    \n",
    "    print_ter(\"-------- FINDING THE BEST MODEL --------\")\n",
    "    scores_at_cvg = get_models_custom_scoring(\n",
    "        candidates_at_cvg, X_train_train, y_train_train, X_train_val, y_train_val)\n",
    "    candidates_params = [cdt.get_params() for cdt in candidates_at_cvg]\n",
    "    \n",
    "    best_svm, best_svm_params, best_svm_scores =\\\n",
    "        get_best_model(candidates_at_cvg, candidates_params, scores_at_cvg, criterion=\"validation_score\") \n",
    "    \n",
    "    write_model_to_leaderboard(best_svm,\n",
    "                               name,\n",
    "                               best_svm_scores[\"training_score\"],\n",
    "                               best_svm_scores[\"validation_score\"],\n",
    "                               comments=comments\n",
    "                              )\n",
    "    return best_svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models_archives/svm_extreme_no_PCA.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-dadec0ac6e28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         seed=101)\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mbest_svm_extreme\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'svm_extreme_no_PCA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-115-ad1d7e3069a9>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".joblib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{name}.joblib\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models_archives/svm_extreme_no_PCA.joblib'"
     ]
    }
   ],
   "source": [
    "### SVM with only extreme values without PCA\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "CREATE_SVM_EXTREME = False\n",
    "\n",
    "# Create input arrays\n",
    "def make_input_svm_extreme(h5_file):\n",
    "    return make_input(h5_file, features=FEATURES, quantiles=TAIL_QUANTILES, dist_char=False, truncate_dist=False)\n",
    "\n",
    "svm_extreme_params_grid_rbf_and_sigmoid = ParameterGrid(\n",
    "    {\"kernel\": [\"rbf\", \"sigmoid\"],\n",
    "     \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "     \"gamma\": [\"auto\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "svm_extreme_params_grid_polynomial = ParameterGrid(\n",
    "    {\"kernel\": [\"poly\"],\n",
    "     \"C\": [0.1, 1, 10],\n",
    "     \"degree\": [1, 2, 3, 4] #if max_iter != -1\n",
    "    })\n",
    "\n",
    "svm_extreme_params_grid = list(svm_extreme_params_grid_rbf_and_sigmoid) + list(svm_extreme_params_grid_polynomial)\n",
    "\n",
    "if CREATE_SVM_EXTREME:\n",
    "   \n",
    "    svm_no_PCA_selector(\n",
    "        make_input_func=make_input_svm_extreme,\n",
    "        params_grid=svm_extreme_params_grid,\n",
    "        scaler=StandardScaler(),\n",
    "        name='svm_extreme_selected_100',\n",
    "        comments=\"tailing quantiles; no distribution chars; all features; no PCA; seed=101\",\n",
    "        select=5,\n",
    "        max_iter=100,\n",
    "        seed=101)\n",
    "    \n",
    "best_svm_extreme = load_model('svm_extreme_no_PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models_archives/svm_central_selected_100.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-361a387795ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         )\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mbest_svm_central\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'svm_central_selected_100'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-115-ad1d7e3069a9>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".joblib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{name}.joblib\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models_archives/svm_central_selected_100.joblib'"
     ]
    }
   ],
   "source": [
    "### SVM with only extreme values without PCA\n",
    "CREATE_SVM_CENTRAL = False\n",
    "\n",
    "# Create input arrays\n",
    "def make_input_svm_central(h5_file):\n",
    "    return make_input(h5_file, features=FEATURES, quantiles=list(), dist_char=True, truncate_dist=True)\n",
    "\n",
    "svm_central_grid_1 = ParameterGrid(\n",
    "    {\"kernel\": [\"rbf\", \"sigmoid\"],\n",
    "     \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "     \"gamma\": [\"auto\", \"scale\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "svm_central_grid_2 = ParameterGrid(\n",
    "    {\"kernel\": [\"poly\"],\n",
    "     \"C\": [0.1, 1, 10],\n",
    "     \"degree\": [1, 2, 3, 4] #if max_iter != -1\n",
    "    })\n",
    "\n",
    "svm_central_grid = list(svm_central_grid_1) + list(svm_central_grid_2)\n",
    "\n",
    "if CREATE_SVM_CENTRAL:\n",
    "    best_svm_central = \\\n",
    "        svm_no_PCA_selector(\n",
    "            make_input_func=make_input_svm_central,\n",
    "            params_grid=svm_central_grid,\n",
    "            scaler=StandardScaler(),\n",
    "            name='svm_central_selected_100',\n",
    "            comments=\"no quantiles; dist chars with truncation; all features; no PCA; seed=101\",\n",
    "            select=5, \n",
    "            max_iter=100,\n",
    "            seed=101\n",
    "        )\n",
    "    \n",
    "best_svm_central = load_model('svm_central_selected_100')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- (PRE-)TRAINING --------\n",
      "Training Model #1/32 [ETA: ?]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #2/32 [ETA: 701.77s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #3/32 [ETA: 563.45s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #4/32 [ETA: 598.58s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #5/32 [ETA: 590.91s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #6/32 [ETA: 590.05s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #7/32 [ETA: 568.27s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #8/32 [ETA: 545.31s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #9/32 [ETA: 523.23s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #10/32 [ETA: 487.99s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #11/32 [ETA: 453.0s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #12/32 [ETA: 432.8s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #13/32 [ETA: 414.13s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #14/32 [ETA: 400.33s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #15/32 [ETA: 381.34s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #16/32 [ETA: 361.34s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #17/32 [ETA: 338.35s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #18/32 [ETA: 321.0s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #19/32 [ETA: 301.51s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #20/32 [ETA: 282.08s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #21/32 [ETA: 261.98s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #22/32 [ETA: 241.75s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #23/32 [ETA: 219.63s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #24/32 [ETA: 198.99s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #25/32 [ETA: 177.66s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #26/32 [ETA: 155.3s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #27/32 [ETA: 133.19s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #28/32 [ETA: 110.55s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #29/32 [ETA: 88.53s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #30/32 [ETA: 66.73s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #31/32 [ETA: 44.52s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #32/32 [ETA: 22.28s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------- CROSS-VALIDATION --------\n",
      "Scoring Model #32/32 [ETA: 37.54s]\u001b[1KK\n",
      "-------- SELECTION --------\n",
      "\n",
      "-------- TRAINING CANDIDATES UNTIL CONVERGENCE --------\n",
      "TRAINING UNTIL CONVERGENCE : MODEL #5/5 [ETA: 45.98s\u001b[1KK\n",
      "-------- FINDING THE BEST MODEL --------\n",
      "New model saved at models_archives/svm_glouton_selected_1000.joblib\n"
     ]
    }
   ],
   "source": [
    "### SVM with only extreme values without PCA\n",
    "CREATE_SVM_GLOUTON = False\n",
    "\n",
    "# Create input arrays\n",
    "def make_input_svm_glouton(h5_file):\n",
    "    return make_input(h5_file, features=FEATURES, quantiles=TAIL_QUANTILES, dist_char=True, truncate_dist=True)\n",
    "\n",
    "svm_glouton_grid_1 = ParameterGrid(\n",
    "    {\"kernel\": [\"rbf\", \"sigmoid\"],\n",
    "     \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "     \"gamma\": [\"auto\", \"scale\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "svm_glouton_grid_2 = ParameterGrid(\n",
    "    {\"kernel\": [\"poly\"],\n",
    "     \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "     \"degree\": [1, 2, 3, 4] #if max_iter != -1\n",
    "    })\n",
    "\n",
    "svm_glouton_grid = list(svm_glouton_grid_1) + list(svm_glouton_grid_2)\n",
    "\n",
    "if CREATE_SVM_GLOUTON:\n",
    "    best_svm_glouton = \\\n",
    "        svm_no_PCA_selector(\n",
    "            make_input_func=make_input_svm_glouton,\n",
    "            params_grid=svm_glouton_grid,\n",
    "            scaler=StandardScaler(),\n",
    "            name='svm_glouton_selected_1000',\n",
    "            comments=\"tail quantiles; dist chars with truncation; all features; no PCA; seed=101\",\n",
    "            select=5, \n",
    "            max_iter=1000,\n",
    "            seed=101\n",
    "        )\n",
    "    \n",
    "# best_svm_glouton = load_model('svm_glouton_selected_100')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_inputs_svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-d0d8284c6380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mX_train_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mget_inputs_svm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_input_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_inputs_svm' is not defined"
     ]
    }
   ],
   "source": [
    "# svm_central = load_model(\"svm_central_selected_100.joblib\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def make_input_rf(h5_file):\n",
    "    return make_input(h5_file, features=FEATURES, quantiles=QUANTILES, dist_char=True, truncate_dist=True)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "X_train_train, y_train_train, X_train_val, y_train_val, X_test = \\\n",
    "    get_inputs_svm(make_input_rf, StandardScaler(), seed=101)\n",
    "\n",
    "rf.fit(X_train_train, y_train_train)\n",
    "y_rf = rf.predict(X_test)\n",
    "\n",
    "\n",
    "# y_pred = svm_central.predict(X_test)\n",
    "# submit_to_kaggle(y_rf, h5_test, fname=\"soumission_rf_noob.csv\", msg=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New submission file at submissions/soumission_rf_noob.csv\n"
     ]
    }
   ],
   "source": [
    "# submit_to_kaggle(y_rf, h5_test, fname=\"soumission_rf_noob.csv\", msg=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature #31/32\u001b[1K\r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.int64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-eec622ce8fba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mMODEL_FEATURES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mLOG_ENERGY_FEATURES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pulse_max_freq\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pulse_max_logE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"speed_norm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accel_norm\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVM_FEATURES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mQUANTILES_TAIL_CAPTURE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVM_FEATURES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mQUANTILES_TAIL_CAPTURE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-2a8f315e7c88>\u001b[0m in \u001b[0;36mmake_input\u001b[0;34m(h5_file, features, quantiles, dist_char, truncate_dist, rescale)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_subject_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubjects_ids_to_indexers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_boolean_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mz_scaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0minput_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-111-0eccaa70d706>\u001b[0m in \u001b[0;36msubjects_ids_to_indexers\u001b[0;34m(h5_file, subjects_ids, as_indices, as_boolean_array)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Choose between `indices` and `boolean array` representations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mas_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mboundaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_subject_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mready_to_use\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubjects_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mas_boolean_array\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.int64' object is not iterable"
     ]
    }
   ],
   "source": [
    "# make input for SVM\n",
    "LOG_ENERGY_FEATURES = [feature for feature in FEATURES if feature.endswith(\"logE\") and \"eeg\" in feature]\n",
    "\n",
    "MODEL_FEATURES = [*LOG_ENERGY_FEATURES, \"pulse_max_freq\", \"pulse_max_logE\", \"speed_norm\", \"accel_norm\"]\n",
    "\n",
    "X_train = make_input(h5_train, features=SVM_FEATURES, quantiles=QUANTILES_TAIL_CAPTURE)\n",
    "X_test = make_input(h5_test, features=SVM_FEATURES, quantiles=QUANTILES_TAIL_CAPTURE)\n",
    "\n",
    "train_ids, validation_ids = split_train_validation_subject_ids(0.7, seed=101)\n",
    "X_train_train, y_train_train, X_train_val, y_train_val = split_train_validation(X_train, train_subjects_ids=train_ids)\n",
    "\n",
    "### PCA on log_energy features\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_logE = PCA(0.9)\n",
    "pca_logE.fit(X_train_train[:, :len(LOG_ENERGY_FEATURES)])\n",
    "\n",
    "def apply_pca(X, pca, copy=True):\n",
    "    if copy:\n",
    "        return apply_pca(X[:, :], pca, copy=False)\n",
    "    X_transformed = pca.transform(X[:, :len(LOG_ENERGY_FEATURES)])\n",
    "    X[:, len(LOG_ENERGY_FEATURES) - pca.n_components_ : len(LOG_ENERGY_FEATURES)] = X_transformed\n",
    "    X = X[:, len(LOG_ENERGY_FEATURES) - pca.n_components_ :]\n",
    "    return X\n",
    "\n",
    "X_train_train = apply_pca(X_train_train, pca_logE)\n",
    "X_train_val = apply_pca(X_train_val, pca_logE)\n",
    "X_test = apply_pca(X_test, pca_logE)\n",
    "\n",
    "### Rescaling\n",
    "#from sklearn.preprocessing import StandardScaler \n",
    "# already robust on not logE features because we take quantiles\n",
    "# --> StandardScaler \n",
    "\n",
    "#z_scaler = StandardScaler()\n",
    "\n",
    "#X_train_train = z_scaler.fit_transform(X_train_train)\n",
    "#X_train_val = z_scaler.transform(X_train_val)\n",
    "#X_test = z_scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVC Models\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_params_grid_rbf_and_sigmoid = ParameterGrid(\n",
    "    {\"kernel\": [\"rbf\", \"sigmoid\"],\n",
    "     \"C\": [0.1, 1, 10],\n",
    "     \"gamma\": [\"scale\", \"auto\"]\n",
    "    })\n",
    "\n",
    "svm_params_grid_poly = ParameterGrid(\n",
    "    {\"kernel\": [\"poly\"],\n",
    "     \"C\": [0.1, 1, 10],\n",
    "     \"degree\": [3, 10] #if max_iter != -1\n",
    "    })\n",
    " \n",
    "svm_params_grid = list(svm_params_grid_rbf_and_sigmoid) + list(svm_params_grid_poly)\n",
    "\n",
    "svm_models = train_on_grid(SVC, svm_params_grid, X_train_train, y_train_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Model #17/18 [ETA: 16.0s]\u001b[1KKK\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train_macro': 0.34906001481735155,\n",
       "  'train_micro': 0.5051310682192801,\n",
       "  'validation_macro': 0.2763904479917661,\n",
       "  'validation_micro': 0.4335997279374256},\n",
       " {'train_macro': 0.2614320675993827,\n",
       "  'train_micro': 0.369011538257032,\n",
       "  'validation_macro': 0.25364166732316773,\n",
       "  'validation_micro': 0.3479000170039109},\n",
       " {'train_macro': 0.34906001481735155,\n",
       "  'train_micro': 0.5051310682192801,\n",
       "  'validation_macro': 0.2763904479917661,\n",
       "  'validation_micro': 0.4335997279374256},\n",
       " {'train_macro': 0.2614320675993827,\n",
       "  'train_micro': 0.369011538257032,\n",
       "  'validation_macro': 0.25364166732316773,\n",
       "  'validation_micro': 0.3479000170039109},\n",
       " {'train_macro': 0.4425298480449335,\n",
       "  'train_micro': 0.5605891423406179,\n",
       "  'validation_macro': 0.3625099634566772,\n",
       "  'validation_micro': 0.4762795442951879},\n",
       " {'train_macro': 0.2701379314099138,\n",
       "  'train_micro': 0.352634657308449,\n",
       "  'validation_macro': 0.2471371194507579,\n",
       "  'validation_micro': 0.3239245026356062},\n",
       " {'train_macro': 0.4425298480449335,\n",
       "  'train_micro': 0.5605891423406179,\n",
       "  'validation_macro': 0.3625099634566772,\n",
       "  'validation_micro': 0.4762795442951879},\n",
       " {'train_macro': 0.2701379314099138,\n",
       "  'train_micro': 0.352634657308449,\n",
       "  'validation_macro': 0.2471371194507579,\n",
       "  'validation_micro': 0.3239245026356062},\n",
       " {'train_macro': 0.5804677025683329,\n",
       "  'train_micro': 0.6554474397830595,\n",
       "  'validation_macro': 0.43988329111958446,\n",
       "  'validation_micro': 0.5169188913450093},\n",
       " {'train_macro': 0.26610912090439426,\n",
       "  'train_micro': 0.32881373956505555,\n",
       "  'validation_macro': 0.2544309155178751,\n",
       "  'validation_micro': 0.31389219520489714},\n",
       " {'train_macro': 0.5804677025683329,\n",
       "  'train_micro': 0.6554474397830595,\n",
       "  'validation_macro': 0.43988329111958446,\n",
       "  'validation_micro': 0.5169188913450093},\n",
       " {'train_macro': 0.26610912090439426,\n",
       "  'train_micro': 0.32881373956505555,\n",
       "  'validation_macro': 0.2544309155178751,\n",
       "  'validation_micro': 0.31389219520489714},\n",
       " {'train_macro': 0.3102744686201169,\n",
       "  'train_micro': 0.47982134311692454,\n",
       "  'validation_macro': 0.2327523496164874,\n",
       "  'validation_micro': 0.42373745961571163},\n",
       " {'train_macro': 0.41343745072922006,\n",
       "  'train_micro': 0.5233689583665656,\n",
       "  'validation_macro': 0.2101554504624652,\n",
       "  'validation_micro': 0.4091140962421357},\n",
       " {'train_macro': 0.363033653057082,\n",
       "  'train_micro': 0.505237411602063,\n",
       "  'validation_macro': 0.2592401077761147,\n",
       "  'validation_micro': 0.4301989457575242},\n",
       " {'train_macro': 0.4743140832015283,\n",
       "  'train_micro': 0.5573988408571277,\n",
       "  'validation_macro': 0.22802604748807948,\n",
       "  'validation_micro': 0.4111545655500765},\n",
       " {'train_macro': 0.434813429878487,\n",
       "  'train_micro': 0.5451161801456904,\n",
       "  'validation_macro': 0.29331375382746516,\n",
       "  'validation_micro': 0.42373745961571163},\n",
       " {'train_macro': 0.5377520855415243,\n",
       "  'train_micro': 0.5945126814483969,\n",
       "  'validation_macro': 0.25912130946572165,\n",
       "  'validation_micro': 0.4191464036728448}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_scores = get_models_custom_scoring(svm_models, X_train_train, y_train_train, X_train_val, y_train_val)\n",
    "svm_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-c626ed281ed3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvm_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_svm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_svm_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_svm_scores\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mget_best_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_params_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"validation_macro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_svm_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "best_svm_model, best_svm_params, best_svm_scores = \\\n",
    "    get_best_model(svm_models, svm_params_grid, svm_scores, criterion=\"validation_weighted\")\n",
    "best_svm_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #48/48 [ETA: 4.11s]\u001b[1KK\r"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "random_forest_params = {\n",
    "    \"n_estimators\": [10, 30, 100, 150],\n",
    "    \"max_depth\": [3, 10, 30, 100],\n",
    "    \"min_samples_leaf\": [1, 10, 100]}\n",
    "\n",
    "random_forest_params_grid = list(ParameterGrid(random_forest_params))\n",
    "\n",
    "random_forest_models = train_on_grid(\n",
    "    RandomForestClassifier, \n",
    "    random_forest_params_grid,\n",
    "    X_train_train,\n",
    "    y_train_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Model #47/48 [ETA: 0.15s]\u001b[1K\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">params</th>\n",
       "      <th colspan=\"2\" halign=\"left\">scores</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>train_weighted</th>\n",
       "      <th>validation_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>0.643324</td>\n",
       "      <td>0.463518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.632910</td>\n",
       "      <td>0.463180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.645184</td>\n",
       "      <td>0.459087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.636848</td>\n",
       "      <td>0.458153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.642077</td>\n",
       "      <td>0.458108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.650043</td>\n",
       "      <td>0.455831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>0.644333</td>\n",
       "      <td>0.452113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.776089</td>\n",
       "      <td>0.451573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.625828</td>\n",
       "      <td>0.448405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.730110</td>\n",
       "      <td>0.448180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.605076</td>\n",
       "      <td>0.446696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.642172</td>\n",
       "      <td>0.446280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.777016</td>\n",
       "      <td>0.445642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.733018</td>\n",
       "      <td>0.445101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.773608</td>\n",
       "      <td>0.443539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>0.736907</td>\n",
       "      <td>0.442927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.861906</td>\n",
       "      <td>0.440397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.620544</td>\n",
       "      <td>0.439826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>0.627548</td>\n",
       "      <td>0.435553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.848140</td>\n",
       "      <td>0.431173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>0.866251</td>\n",
       "      <td>0.428421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.867118</td>\n",
       "      <td>0.428166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.715539</td>\n",
       "      <td>0.426722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.865487</td>\n",
       "      <td>0.426040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.771079</td>\n",
       "      <td>0.425536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>0.867630</td>\n",
       "      <td>0.425310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.421711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.421072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.419689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.861385</td>\n",
       "      <td>0.418482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.852121</td>\n",
       "      <td>0.417446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.417376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.993775</td>\n",
       "      <td>0.409579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.999362</td>\n",
       "      <td>0.407556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.999415</td>\n",
       "      <td>0.406882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.430079</td>\n",
       "      <td>0.398412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.426527</td>\n",
       "      <td>0.397599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.423867</td>\n",
       "      <td>0.396972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.423755</td>\n",
       "      <td>0.396174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.427860</td>\n",
       "      <td>0.396089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>0.424250</td>\n",
       "      <td>0.395990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.427091</td>\n",
       "      <td>0.395918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>0.428306</td>\n",
       "      <td>0.395441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.993130</td>\n",
       "      <td>0.394673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.422541</td>\n",
       "      <td>0.393717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.421754</td>\n",
       "      <td>0.391809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.415593</td>\n",
       "      <td>0.376588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.381092</td>\n",
       "      <td>0.347265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      params                                       scores                    \n",
       "   max_depth min_samples_leaf n_estimators train_weighted validation_weighted\n",
       "33        30              100           30       0.643324            0.463518\n",
       "44       100              100           10       0.632910            0.463180\n",
       "47       100              100          150       0.645184            0.459087\n",
       "32        30              100           10       0.636848            0.458153\n",
       "35        30              100          150       0.642077            0.458108\n",
       "46       100              100          100       0.650043            0.455831\n",
       "45       100              100           30       0.644333            0.452113\n",
       "13        10                1           30       0.776089            0.451573\n",
       "22        10              100          100       0.625828            0.448405\n",
       "18        10               10          100       0.730110            0.448180\n",
       "20        10              100           10       0.605076            0.446696\n",
       "34        30              100          100       0.642172            0.446280\n",
       "15        10                1          150       0.777016            0.445642\n",
       "17        10               10           30       0.733018            0.445101\n",
       "14        10                1          100       0.773608            0.443539\n",
       "19        10               10          150       0.736907            0.442927\n",
       "29        30               10           30       0.861906            0.440397\n",
       "23        10              100          150       0.620544            0.439826\n",
       "21        10              100           30       0.627548            0.435553\n",
       "40       100               10           10       0.848140            0.431173\n",
       "31        30               10          150       0.866251            0.428421\n",
       "30        30               10          100       0.867118            0.428166\n",
       "16        10               10           10       0.715539            0.426722\n",
       "42       100               10          100       0.865487            0.426040\n",
       "12        10                1           10       0.771079            0.425536\n",
       "43       100               10          150       0.867630            0.425310\n",
       "26        30                1          100       0.999947            0.421711\n",
       "38       100                1          100       1.000000            0.421072\n",
       "27        30                1          150       1.000000            0.419689\n",
       "41       100               10           30       0.861385            0.418482\n",
       "28        30               10           10       0.852121            0.417446\n",
       "39       100                1          150       1.000000            0.417376\n",
       "24        30                1           10       0.993775            0.409579\n",
       "37       100                1           30       0.999362            0.407556\n",
       "25        30                1           30       0.999415            0.406882\n",
       "5          3               10           30       0.430079            0.398412\n",
       "10         3              100          100       0.426527            0.397599\n",
       "8          3              100           10       0.423867            0.396972\n",
       "11         3              100          150       0.423755            0.396174\n",
       "6          3               10          100       0.427860            0.396089\n",
       "9          3              100           30       0.424250            0.395990\n",
       "3          3                1          150       0.427091            0.395918\n",
       "7          3               10          150       0.428306            0.395441\n",
       "36       100                1           10       0.993130            0.394673\n",
       "1          3                1           30       0.422541            0.393717\n",
       "2          3                1          100       0.421754            0.391809\n",
       "0          3                1           10       0.415593            0.376588\n",
       "4          3               10           10       0.381092            0.347265"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_scores = get_models_custom_scoring(\n",
    "    random_forest_models,\n",
    "    X_train_train,\n",
    "    y_train_train,\n",
    "    X_train_val,\n",
    "    y_train_val\n",
    ")\n",
    "                   \n",
    "random_forest_results = pd.concat([pd.DataFrame(random_forest_params_grid), pd.DataFrame(random_forest_scores)],\n",
    "                                  keys=['params', 'scores'],\n",
    "                                  axis=1)\n",
    "\n",
    "random_forest_results = random_forest_results.sort_values(\n",
    "    by=[('scores', 'validation_weighted')], \n",
    "    ascending=False\n",
    ")\n",
    "random_forest_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_forest_model, _, _ = get_best_model(random_forest_models, random_forest_params_grid, random_forest_scores)\n",
    "    \n",
    "random_forest_prediction = best_random_forest_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New submission file at submission_rf.csv\n"
     ]
    }
   ],
   "source": [
    "from kaggle_submit import submit_to_kaggle\n",
    "\n",
    "# submit_to_kaggle(random_forest_prediction, h5_test, fname=\"submission_rf.csv\", msg=\"rf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_train.close()\n",
    "h5_test.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
