{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "from kaggle_submit import submit_to_kaggle\n",
    "from helpers import *\n",
    "\n",
    "PICTURES_FOLDER = \"pictures\"\n",
    "os.makedirs(PICTURES_FOLDER, exist_ok=True)\n",
    "\n",
    "SLEEP_STAGES_COLORS = {\n",
    "    0: \"blue\",\n",
    "    1: \"green\",     \n",
    "    2: \"red\",\n",
    "    3: \"black\",\n",
    "    4: \"orange\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"kaggle_data/X_train.h5/X_train.h5\"\n",
    "test_file = \"kaggle_data/X_test.h5/X_test.h5\"\n",
    "\n",
    "h5_train = h5py.File(train_file, mode='a')\n",
    "h5_test = h5py.File(test_file, mode='a')\n",
    "\n",
    "y_train = pd.read_csv(\"kaggle_data/y_train.csv\", index_col=0, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES (sorted) = ['accel_norm', 'alpha_eeg_1_logE', 'alpha_eeg_2_logE', 'alpha_eeg_3_logE', 'alpha_eeg_4_logE', 'alpha_eeg_5_logE', 'alpha_eeg_6_logE', 'alpha_eeg_7_logE', 'beta_eeg_1_logE', 'beta_eeg_2_logE', 'beta_eeg_3_logE', 'beta_eeg_4_logE', 'beta_eeg_5_logE', 'beta_eeg_6_logE', 'beta_eeg_7_logE', 'delta_eeg_1_logE', 'delta_eeg_2_logE', 'delta_eeg_3_logE', 'delta_eeg_4_logE', 'delta_eeg_5_logE', 'delta_eeg_6_logE', 'delta_eeg_7_logE', 'eeg_1', 'eeg_2', 'eeg_3', 'eeg_4', 'eeg_5', 'eeg_6', 'eeg_7', 'pulse', 'pulse_max_freq', 'pulse_max_logE', 'sleep_left', 'sleep_time', 'sleep_time_relative', 'speed_norm', 'theta_eeg_1_logE', 'theta_eeg_2_logE', 'theta_eeg_3_logE', 'theta_eeg_4_logE', 'theta_eeg_5_logE', 'theta_eeg_6_logE', 'theta_eeg_7_logE']\n"
     ]
    }
   ],
   "source": [
    "IRRELEVANT_FEATURES = ['index', 'index_absolute', 'index_window',\n",
    "                       'x', 'y', 'z',\n",
    "                       'speed_x', 'speed_y', 'speed_z',\n",
    "                       #'eeg_1', 'eeg_2','eeg_3','eeg_4','eeg_5', 'eeg_6', 'eeg_7',\n",
    "                       #'pulse',\n",
    "                      ]\n",
    "\n",
    "def update_globals():\n",
    "    features = [feat for feat in h5_train.keys() if feat not in IRRELEVANT_FEATURES]\n",
    "    frequencies = {feat: h5_train[feat][0].size // 30 for feat in features}\n",
    "    frequencies = {feat: freq if int(freq) in (10, 50) else 0 \n",
    "                   for feat, freq in frequencies.items()}\n",
    "    return features, frequencies\n",
    "    \n",
    "FEATURES, FREQUENCIES = update_globals()\n",
    "print(\"FEATURES (sorted) =\", sorted(FEATURES))\n",
    "# print(\"FREQUENCIES =\", FREQUENCIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# get_subject_feature_signals(h5_train, 1, \"eeg_1\", frequencies_dict=FREQUENCIES, as_timeseries=False)\n",
    "# get_subject_feature_signals(h5_train, 1, \"eeg_1\", frequencies_dict=FREQUENCIES, as_timeseries=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accel_norm', 'alpha_eeg_1_logE', 'alpha_eeg_2_logE', 'alpha_eeg_3_logE', 'alpha_eeg_4_logE', 'alpha_eeg_5_logE', 'alpha_eeg_6_logE', 'alpha_eeg_7_logE', 'beta_eeg_1_logE', 'beta_eeg_2_logE', 'beta_eeg_3_logE', 'beta_eeg_4_logE', 'beta_eeg_5_logE', 'beta_eeg_6_logE', 'beta_eeg_7_logE', 'delta_eeg_1_logE', 'delta_eeg_2_logE', 'delta_eeg_3_logE', 'delta_eeg_4_logE', 'delta_eeg_5_logE', 'delta_eeg_6_logE', 'delta_eeg_7_logE', 'eeg_1', 'eeg_2', 'eeg_3', 'eeg_4', 'eeg_5', 'eeg_6', 'eeg_7', 'pulse', 'pulse_max_freq', 'pulse_max_logE', 'sleep_left', 'sleep_time', 'sleep_time_relative', 'speed_norm', 'theta_eeg_1_logE', 'theta_eeg_2_logE', 'theta_eeg_3_logE', 'theta_eeg_4_logE', 'theta_eeg_5_logE', 'theta_eeg_6_logE', 'theta_eeg_7_logE']\n"
     ]
    }
   ],
   "source": [
    "from speed_and_accel import _create_speed_and_acceleration\n",
    "\n",
    "# Create speed and acceleration\n",
    "_create_speed_and_acceleration(h5_train, overwrite=False, verbose=True)\n",
    "_create_speed_and_acceleration(h5_test, overwrite=False, verbose=True)\n",
    "FEATURES, FREQUENCIES = update_globals()\n",
    "print(FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accel_norm', 'alpha_eeg_1_logE', 'alpha_eeg_2_logE', 'alpha_eeg_3_logE', 'alpha_eeg_4_logE', 'alpha_eeg_5_logE', 'alpha_eeg_6_logE', 'alpha_eeg_7_logE', 'beta_eeg_1_logE', 'beta_eeg_2_logE', 'beta_eeg_3_logE', 'beta_eeg_4_logE', 'beta_eeg_5_logE', 'beta_eeg_6_logE', 'beta_eeg_7_logE', 'delta_eeg_1_logE', 'delta_eeg_2_logE', 'delta_eeg_3_logE', 'delta_eeg_4_logE', 'delta_eeg_5_logE', 'delta_eeg_6_logE', 'delta_eeg_7_logE', 'eeg_1', 'eeg_2', 'eeg_3', 'eeg_4', 'eeg_5', 'eeg_6', 'eeg_7', 'pulse', 'pulse_max_freq', 'pulse_max_logE', 'sleep_left', 'sleep_time', 'sleep_time_relative', 'speed_norm', 'theta_eeg_1_logE', 'theta_eeg_2_logE', 'theta_eeg_3_logE', 'theta_eeg_4_logE', 'theta_eeg_5_logE', 'theta_eeg_6_logE', 'theta_eeg_7_logE']\n"
     ]
    }
   ],
   "source": [
    "from time_features import _create_time_features\n",
    "\n",
    "_create_time_features(h5_train, overwrite=False, verbose=True)\n",
    "_create_time_features(h5_test, overwrite=False, verbose=True)\n",
    "\n",
    "FEATURES, FREQUENCIES = update_globals()\n",
    "print(FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Name     | Frequency (Hz)|\n",
    "| ---------| -----------|\n",
    "| $\\delta$ | 0-4 |\n",
    "| $\\theta$ | 4-8 |\n",
    "| $\\alpha$ | 8-13 |\n",
    "| $\\beta$  | 13-22 |\n",
    "| $\\gamma$ | 30-. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQUENCIES = {'accel_norm': 10, 'alpha_eeg_1_logE': 0, 'alpha_eeg_2_logE': 0, 'alpha_eeg_3_logE': 0, 'alpha_eeg_4_logE': 0, 'alpha_eeg_5_logE': 0, 'alpha_eeg_6_logE': 0, 'alpha_eeg_7_logE': 0, 'beta_eeg_1_logE': 0, 'beta_eeg_2_logE': 0, 'beta_eeg_3_logE': 0, 'beta_eeg_4_logE': 0, 'beta_eeg_5_logE': 0, 'beta_eeg_6_logE': 0, 'beta_eeg_7_logE': 0, 'delta_eeg_1_logE': 0, 'delta_eeg_2_logE': 0, 'delta_eeg_3_logE': 0, 'delta_eeg_4_logE': 0, 'delta_eeg_5_logE': 0, 'delta_eeg_6_logE': 0, 'delta_eeg_7_logE': 0, 'eeg_1': 50, 'eeg_2': 50, 'eeg_3': 50, 'eeg_4': 50, 'eeg_5': 50, 'eeg_6': 50, 'eeg_7': 50, 'pulse': 10, 'pulse_max_freq': 0, 'pulse_max_logE': 0, 'sleep_left': 0, 'sleep_time': 0, 'sleep_time_relative': 0, 'speed_norm': 10, 'theta_eeg_1_logE': 0, 'theta_eeg_2_logE': 0, 'theta_eeg_3_logE': 0, 'theta_eeg_4_logE': 0, 'theta_eeg_5_logE': 0, 'theta_eeg_6_logE': 0, 'theta_eeg_7_logE': 0}\n"
     ]
    }
   ],
   "source": [
    "from eeg_band_log_energies import _create_log_energy\n",
    "\n",
    "_create_log_energy(h5_train, n_chunks=100, overwrite=False, verbose=True)\n",
    "_create_log_energy(h5_test, n_chunks=100, overwrite=False, verbose=True)\n",
    "FEATURES, FREQUENCIES = update_globals()\n",
    "# print(\"FEATURES =\", FEATURES)\n",
    "print(\"FREQUENCIES =\", FREQUENCIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accel_norm', 'alpha_eeg_1_logE', 'alpha_eeg_2_logE', 'alpha_eeg_3_logE', 'alpha_eeg_4_logE', 'alpha_eeg_5_logE', 'alpha_eeg_6_logE', 'alpha_eeg_7_logE', 'beta_eeg_1_logE', 'beta_eeg_2_logE', 'beta_eeg_3_logE', 'beta_eeg_4_logE', 'beta_eeg_5_logE', 'beta_eeg_6_logE', 'beta_eeg_7_logE', 'delta_eeg_1_logE', 'delta_eeg_2_logE', 'delta_eeg_3_logE', 'delta_eeg_4_logE', 'delta_eeg_5_logE', 'delta_eeg_6_logE', 'delta_eeg_7_logE', 'eeg_1', 'eeg_2', 'eeg_3', 'eeg_4', 'eeg_5', 'eeg_6', 'eeg_7', 'pulse', 'pulse_max_freq', 'pulse_max_logE', 'sleep_left', 'sleep_time', 'sleep_time_relative', 'speed_norm', 'theta_eeg_1_logE', 'theta_eeg_2_logE', 'theta_eeg_3_logE', 'theta_eeg_4_logE', 'theta_eeg_5_logE', 'theta_eeg_6_logE', 'theta_eeg_7_logE']\n"
     ]
    }
   ],
   "source": [
    "from pulse_to_freq import _create_pulse_max_log_energy_and_freq\n",
    "\n",
    "_create_pulse_max_log_energy_and_freq(h5_train, n_chunks=100, overwrite=False, verbose=True)\n",
    "_create_pulse_max_log_energy_and_freq(h5_test, n_chunks=100, overwrite=False, verbose=True)\n",
    "\n",
    "FEATURES, FREQUENCIES = update_globals()\n",
    "print(FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def robust_rescale(df):\n",
    "    \"\"\"\n",
    "    X_rescaled = (X - MED(X)) / MED(|X - MED(X)|)\n",
    "    \"\"\"\n",
    "    med = df.median()\n",
    "    med_spread = (df - df.median()).abs().median()\n",
    "    # df_rescaled = (df - med) / med_spread\n",
    "    return (df - med) / med_spread\n",
    "\n",
    "def min_max_rescale(df):\n",
    "    min_ = df.min()\n",
    "    max_ = df.max()\n",
    "    return (df - min_) / (max_ - min_)\n",
    "    \n",
    "def z_rescale(df): \n",
    "    mean = df.mean()\n",
    "    std = df.std()\n",
    "    return (df - mean) / std\n",
    "\n",
    "def get_fig_subjects():\n",
    "    fig, axes = plt.subplots(10, 3, figsize=(10, 40))\n",
    "    return fig, np.ravel(axes)\n",
    "\n",
    "def title_with_subject_id(ax, subject_id):\n",
    "    ax.set_title(f'SUBJECT #{subject_id}')\n",
    "    return None\n",
    "\n",
    "def save_feature_quantiles(feature,\n",
    "                           inf_qt=0.025,\n",
    "                           sup_qt=0.975,\n",
    "                           n_quantiles=21,\n",
    "                           robust_rescaling=False,\n",
    "                           overwrite=False,\n",
    "                           verbose=True):\n",
    "    \"\"\"\n",
    "    See pictures/quantile_plots\n",
    "    \n",
    "    Can be improved (make robust and not robust qplots simultaneously)\n",
    "    \"\"\"\n",
    "    # Make directory if it does not exist\n",
    "    qplot_dir = os.path.join(PICTURES_FOLDER, f\"quantile_plots\")\n",
    "    os.makedirs(qplot_dir, exist_ok=True)\n",
    "    # Escape if not overwrite and already done\n",
    "    qplot_fname = os.path.join(qplot_dir, f'{feature}{\"--rescaled\" if robust_rescaling else \"\"}.png')\n",
    "    if (not overwrite) and os.path.exists(qplot_fname):\n",
    "        return None\n",
    "    # Otherwise,\n",
    "    subject_ids = get_subject_ids(h5_train)\n",
    "    quantiles = np.linspace(inf_qt, sup_qt, n_quantiles).round(3)\n",
    "    subjects_quantiles = dict()\n",
    "    for cnt, sid in enumerate(subject_ids):\n",
    "        if verbose:\n",
    "            print_bis(f\"FEATURE #{FEATURES.index(feature)} SUBJECT {cnt+1}/{len(subject_ids)} (RESCALE = {str(robust_rescaling)})\")\n",
    "        # Robust representation of the signal\n",
    "        signal = get_subject_feature_signals(h5_train, sid, feature, frequencies_dict=FREQUENCIES, as_timeseries=False)\n",
    "        size = signal[0].size\n",
    "        signal = pd.Series(np.concatenate(signal))\n",
    "        if robust_rescaling:\n",
    "            signal = robust_rescale(signal)\n",
    "        # Behaviour by sleep stage\n",
    "        sleep_stages = get_subject_sleep_stage(sid, h5_train, y_train).values\n",
    "        signal_by_stage = signal.groupby(np.repeat(sleep_stages, size))\n",
    "        subjects_quantiles[sid] = signal_by_stage.quantile(quantiles).unstack(0)\n",
    "        \n",
    "    fig, axes = get_fig_subjects()\n",
    "    for ax, sid in zip(axes, subject_ids):\n",
    "        subjects_quantiles[sid].plot(ax=ax)#, color=SLEEP_STAGES_COLORS)\n",
    "        title_with_subject_id(ax, sid)\n",
    "    plt.savefig(qplot_fname)\n",
    "    plt.close(fig)\n",
    "    return subjects_quantiles\n",
    "\n",
    "\n",
    "# TO WRITE QUANTILE PLOTS IN pictures/quantile_plots\n",
    "for i, feat in enumerate(FEATURES):\n",
    "    # print_ter(f\"========= FEATURE {i+1}/{len(FEATURES)} =========\")\n",
    "    save_feature_quantiles(feat, robust_rescaling=False, overwrite=False, verbose=True)\n",
    "    save_feature_quantiles(feat, robust_rescaling=True, overwrite=False, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_proba_transition(subject_id=None):\n",
    "    if subject_id:\n",
    "        start, end = get_subject_boundaries(h5_train, subject_id, ready_to_use=False)\n",
    "        y = y_train.loc[start:end]\n",
    "    else: # all subjects\n",
    "        y = y_train.loc[:]\n",
    "    transition_df = pd.DataFrame(data={\"stage\": y, \"stage_after\": y.shift(-1)})\n",
    "    transition_df = transition_df.iloc[:-1] # NaN\n",
    "    transition_df = transition_df.astype(int)\n",
    "    counts = transition_df.groupby([\"stage\", \"stage_after\"]).size()\n",
    "    counts = counts.unstack(1, fill_value=0)\n",
    "    probas = counts.div(counts.sum(axis=1), axis=0)\n",
    "    probas = probas.reindex(range(0, 5), axis=0, fill_value=0)\n",
    "    probas = probas.reindex(range(0, 5), axis=1, fill_value=0)\n",
    "    return probas\n",
    "\n",
    "transition_plots_dir = os.path.join(PICTURES_FOLDER, \"transition_plots\")\n",
    "os.makedirs(transition_plots_dir, exist_ok=True)\n",
    "\n",
    "def save_transition_plots_by_subject(overwrite=False, verbose=True):\n",
    "    fpath = os.path.join(transition_plots_dir, \"transition_matrix_by_subject.png\")\n",
    "    if (not overwrite) and os.path.exists(fpath):\n",
    "        return None\n",
    "    subject_ids = get_subject_ids(h5_train)\n",
    "    fig, axes = get_fig_subjects()\n",
    "    for ax, sid in zip(axes, subject_ids):\n",
    "        if verbose:\n",
    "            print_bis(f\"SUBJECT #{sid}\")\n",
    "        probas = get_proba_transition(subject_id=sid)\n",
    "        sns.heatmap(probas, ax=ax, vmin=0, vmax=1, annot=True)\n",
    "        title_with_subject_id(ax, sid)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(fpath)\n",
    "    plt.close(fig)    \n",
    "    return None\n",
    "\n",
    "def save_transition_plot_global(overwrite=False):\n",
    "    fpath = os.path.join(transition_plots_dir, \"transition_matrix_global.png\")\n",
    "    if (not overwrite) and os.path.exists(fpath):\n",
    "        return None\n",
    "    proba_global = get_proba_transition()\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(proba_global, ax=ax, vmin=0, vmax=1, annot=True)\n",
    "    fig.savefig(fpath)\n",
    "    plt.close(fig)\n",
    "    return None\n",
    "    \n",
    "save_transition_plots_by_subject(overwrite=False)\n",
    "save_transition_plot_global(overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_energies = [feature for feature, freq in FREQUENCIES.items() if freq == 0]\n",
    "log_energies_df = pd.DataFrame({le: h5_train[le][:][:, 0] for le in log_energies})\n",
    "sns.heatmap(log_energies_df.corr(), center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3511\n",
       "1    1671\n",
       "2    9449\n",
       "3    5224\n",
       "4    4833\n",
       "Name: sleep_stage, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_stages_frequencies = y_train.groupby(y_train.values).count()\n",
    "sleep_stages_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features are of 3 kinds\n",
    "\n",
    "MONO_FEATURES = [feat for feat, freq in FREQUENCIES.items() if freq == 0]\n",
    "TIME_FEATURES = ['accel_norm', 'eeg_1', 'eeg_2', 'eeg_3', 'eeg_4', 'eeg_5', 'eeg_6', 'eeg_7', 'pulse', 'speed_norm']\n",
    "SPECTRAL_FEATURES = []\n",
    "assert set(MONO_FEATURES).union(set(TIME_FEATURES)).union(SPECTRAL_FEATURES) ==  set(FEATURES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantiles \n",
    "\n",
    "LOWER_TAIL_QUANTILES = [0.01, 0.025, 0.05]\n",
    "DECILES = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "UPPER_TAIL_QUANTILES = [0.95, 0.975, 0.99]\n",
    "\n",
    "QUANTILES = LOWER_TAIL_QUANTILES + DECILES + UPPER_TAIL_QUANTILES\n",
    "TAIL_QUANTILES = LOWER_TAIL_QUANTILES + UPPER_TAIL_QUANTILES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to create input array\n",
    "\n",
    "# See pywavelets [https://pywavelets.readthedocs.io/en/latest/] for wavelet transform\n",
    "\n",
    "# Extreme values of features have been used --> extreme quantiles are a good idea\n",
    "\n",
    "# It is said in the study that there is a need for large samples to have correct resolution in frequency\n",
    "#    ---> make chunks of 30s windows ??\n",
    "\n",
    "\n",
    "def get_distribution_quantiles(arr, quantiles, **kwargs):\n",
    "    return np.quantile(arr, q=quantiles, axis=1, **kwargs).T\n",
    "\n",
    "\n",
    "def get_distribution_characteristics(arr, truncate_dist=False):\n",
    "    \"\"\"\n",
    "    mean, variance, skewness, kurtosis\n",
    "    \"\"\"\n",
    "    if truncate_dist:\n",
    "        inf = get_distribution_quantiles(arr, 0.01, keepdims=True)\n",
    "        sup = get_distribution_quantiles(arr, 0.99, keepdims=True)\n",
    "        return get_distribution_quantiles(np.clip(arr, inf, sup), truncate_dist=False)\n",
    "    res = np.empty(shape=(arr.shape[0], 4))\n",
    "    res[:, 0] = np.mean(arr, axis=1, keepdims=False) # mean [order 1]\n",
    "    res[:, 1] = np.mean((arr - res[:, [0]]) ** 2, axis=1, keepdims=False) # variance [order 2]\n",
    "    z_var = ( arr - res[:, [0]] ) / res[:, [1]] \n",
    "    res[:, 2] = np.mean(z_var ** 3, axis=1, keepdims=False) # skewness [order 3]\n",
    "    res[:, 3] = np.mean(z_var ** 4, axis=1, keepdims=False) # kurtosis [order 4]\n",
    "    return res\n",
    "\n",
    "\n",
    "def _make_input_multidimensional_feature_chunk(sequences, quantiles=QUANTILES, dist_char=True, truncate_dist=False):\n",
    "    n_samples = sequences.shape[0]\n",
    "    n_cols = len(quantiles) * int(len(quantiles) > 0) + 4 * int(dist_char)\n",
    "    assert n_cols > 0\n",
    "    res = np.empty(shape=(n_samples, n_cols))\n",
    "    res[:, :len(quantiles)] = get_distribution_quantiles(sequences, quantiles)\n",
    "    if dist_char:\n",
    "        res[:, -4:] = get_distribution_characteristics(sequences, truncate_dist=False)\n",
    "    return res\n",
    "        \n",
    "\n",
    "def make_input_multidimensional_feature(h5_file, \n",
    "                                        feature, \n",
    "                                        quantiles=QUANTILES, \n",
    "                                        dist_char=True,\n",
    "                                        truncate_dist=False,\n",
    "                                        n_chunks=100):\n",
    "    n_cols = len(quantiles) * int(len(quantiles) > 0) + 4 * int(dist_char)\n",
    "    feature_array = np.empty(shape=(h5_file[feature].shape[0], n_cols))\n",
    "    for i, j in chunks_iterator(n_chunks, h5_file[feature].shape[0]):\n",
    "        feature_array[i:j, :] = _make_input_multidimensional_feature_chunk(\n",
    "            h5_file[feature][i:j], quantiles, dist_char, truncate_dist)\n",
    "    return feature_array\n",
    "\n",
    "\n",
    "def make_input(h5_file, features=FEATURES, quantiles=QUANTILES, dist_char=True, truncate_dist=False):\n",
    "    n_mono = sum([feat in MONO_FEATURES for feat in features])\n",
    "    n_cols_multi = len(quantiles) + 4 * int(dist_char)\n",
    "    n_cols = n_mono + n_cols_multi * (len(features) - n_mono)\n",
    "    input_arr = np.empty(shape=(h5_file[\"index\"].shape[0], n_cols))\n",
    "    i = 0\n",
    "    for cnt, feat in enumerate(features):\n",
    "        print_bis(f\"Feature #{cnt}/{len(features)}\")\n",
    "        if feat in MONO_FEATURES:\n",
    "            input_arr[:, [i]] = h5_file[feat][:]\n",
    "            i += 1\n",
    "        else:\n",
    "            input_arr[:, i:i+n_cols_multi] = make_input_multidimensional_feature(\n",
    "                h5_file, feat, quantiles, dist_char, truncate_dist)\n",
    "            i += n_cols_multi\n",
    "    return input_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT TRAIN / CROSS VALIDATION\n",
    "\n",
    "def split_train_validation_subject_ids(train_perc, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    subjects_ids = get_subject_ids(h5_train)\n",
    "    shuffled_ids = np.random.permutation(subjects_ids)\n",
    "    N_train = int(np.round(train_perc * len(shuffled_ids)))\n",
    "    train_ids, validation_ids = shuffled_ids[:N_train], shuffled_ids[N_train:]\n",
    "    return sorted(train_ids), sorted(validation_ids)\n",
    "\n",
    "def subjects_ids_to_indexers(h5_file, subjects_ids, as_indices=False, as_boolean_array=False):\n",
    "    if as_indices == as_boolean_array:\n",
    "        raise NameError('Choose between `indices` and `boolean array` representations')\n",
    "    if as_indices:\n",
    "        boundaries = [get_subject_boundaries(h5_file, sid, ready_to_use=False) for sid in subjects_ids]\n",
    "        return sum(map(lambda bounds: list(range(bounds[0], bounds[1]+1)), boundaries), list())\n",
    "    if as_boolean_array:\n",
    "        boolean_indexer = np.zeros(shape=(h5_file[FEATURES[0]].shape[0],), dtype=bool)\n",
    "        for sid in subjects_ids:\n",
    "            boolean_indexer[get_subject_boundaries(h5_file, sid, ready_to_use=True)] = True\n",
    "        return boolean_indexer\n",
    "        \n",
    "    \n",
    "def split_train_validation(X_train, \n",
    "                           train_subjects_ids=None, # ids for train\n",
    "                           train_perc=None,\n",
    "                           seed=None):\n",
    "    if (train_subjects_ids is None) and (train_perc is None):\n",
    "        raise NameError(\"Either `subjects_ids` or `train_perc` must be provided\")\n",
    "    if train_perc is not None:\n",
    "        train_subjects_ids, _ = split_train_validation_subject_ids(train_perc, seed)\n",
    "        return split_train_validation(X_train, train_subjects_ids=train_subjects_ids)\n",
    "    \n",
    "    train_selector = subjects_ids_to_indexers(h5_train, train_subjects_ids, as_boolean_array=True)\n",
    "    X_train_train, y_train_train = X_train[train_selector], y_train.values[train_selector]\n",
    "    X_train_val, y_train_val = X_train[~train_selector], y_train.values[~train_selector]\n",
    "    \n",
    "    return X_train_train, y_train_train, X_train_val, y_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def get_eta_repr(elapsed, iteration, total_iterations):\n",
    "    if iteration == 0:\n",
    "        return \"?\"\n",
    "    else:\n",
    "        eta = (elapsed / iteration) * (total_iterations - iteration)\n",
    "        return str(np.round(eta, 2)) + \"s\"\n",
    "    \n",
    "    \n",
    "def train_on_grid(model_blueprint, params_grid, X, y):\n",
    "    # Random shuffling of parameters for better ETA\n",
    "    shuffled_ix = np.random.permutation(range(len(params_grid))) # for better ETA\n",
    "    \n",
    "    models = [None for _ in range(len(params_grid))] \n",
    "    elapsed_time = 0\n",
    "    time_start = time.time()\n",
    "\n",
    "    for i, ix in enumerate(shuffled_ix):\n",
    "        print_bis(f\"Training Model #{i+1}/{len(params_grid)} \" +\\\n",
    "                  f\"[ETA: {get_eta_repr(time.time() - time_start, i, len(params_grid))}]\")\n",
    "        model = model_blueprint(**params_grid[ix])\n",
    "        model.fit(X, y)\n",
    "                \n",
    "        models[ix] = model\n",
    "        \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def custom_score(y_pred, y_true):\n",
    "    return fbeta_score(y_pred=y_pred,\n",
    "                       y_true=y_true,\n",
    "                       labels=[0, 1, 2, 3, 4],\n",
    "                       average=\"weighted\",\n",
    "                       beta=1)\n",
    "\n",
    "def get_models_custom_scoring(models, X_train_train, y_train_train, X_train_val, y_train_val):\n",
    "    scores = list()\n",
    "    time_start = time.time()\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        eta = get_eta_repr(time.time() - time_start, i, len(models))\n",
    "        print_bis(f\"Scoring Model #{i+1}/{len(models)} [ETA: {eta}]\")\n",
    "        \n",
    "        y_train_pred = model.predict(X_train_train)\n",
    "        y_val_pred = model.predict(X_train_val)\n",
    "        model_scores = {\n",
    "            \"training_score\": custom_score(y_train_pred, y_train_train),\n",
    "            \"validation_score\": custom_score(y_val_pred, y_train_val),\n",
    "        }\n",
    "        \n",
    "        \n",
    "        scores.append(model_scores)\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(models, models_params, models_scores, criterion=\"validation_score\"):\n",
    "    ix_best_score = np.argmax([s[criterion] for s in models_scores])\n",
    "    best_model = models[ix_best_score]\n",
    "    best_model_params = models_params[ix_best_score]\n",
    "    best_model_score = models_scores[ix_best_score]\n",
    "    return best_model, best_model_params, best_model_score\n",
    "\n",
    "def sort_models(models, models_params, models_scores, criterion=\"validation_score\"):\n",
    "    return sorted(zip(models, models_params, models_scores), key=lambda x: x[2][criterion])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE MODEL\n",
    "\n",
    "from joblib import dump, load\n",
    "ARCHIVES_FOLDER = \"models_archives\"\n",
    "if not os.path.exists(ARCHIVES_FOLDER):\n",
    "    os.makedirs(ARCHIVES_FOLDER)\n",
    "\n",
    "def save_model(model, name):\n",
    "    fpath = os.path.join(ARCHIVES_FOLDER, f\"{name}.joblib\")\n",
    "    dump(model, fpath)\n",
    "    print(f\"New model saved at {fpath}\")\n",
    "    return fpath\n",
    "    \n",
    "    \n",
    "def load_model(name):\n",
    "    if not name.startswith(ARCHIVES_FOLDER):\n",
    "        name = os.path.join(ARCHIVES_FOLDER, name)\n",
    "    if not name.endswith(\".joblib\"):\n",
    "        name = f\"{name}.joblib\"\n",
    "    model = load(name)\n",
    "    return model\n",
    "\n",
    "LEADERBOARD_FILE = \"leaderboard.txt\"\n",
    "if not os.path.exists(LEADERBOARD_FILE):\n",
    "    with open(LEADERBOARD_FILE, 'a') as leaderboard:\n",
    "        leaderboard.write(\";;;\".join(['path', 'training_score', 'validation_score', 'comments']))\n",
    "    \n",
    "def write_model_to_leaderboard(model, model_name, train_score, val_score, comments=\"\"):\n",
    "    fpath = save_model(model, model_name)\n",
    "    with open(LEADERBOARD_FILE, \"a\") as leaderboard:\n",
    "        leaderboard.write(\"\\n\" + ';;;'.join([fpath, str(train_score), str(val_score), comments]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this later : sklearn.model_selection.HalvingRandomSearchCV\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def get_inputs_svm(make_input_func, scaler, seed=None):\n",
    "    X_train = make_input_func(h5_train)\n",
    "    X_test = make_input_func(h5_test)\n",
    "\n",
    "    train_ids, validation_ids = split_train_validation_subject_ids(0.7, seed=seed)\n",
    "    X_train_train, y_train_train, X_train_val, y_train_val = split_train_validation(\n",
    "        X_train, train_subjects_ids=train_ids)\n",
    "\n",
    "\n",
    "    X_train_train = scaler.fit_transform(X_train_train)\n",
    "    X_train_val = scaler.transform(X_train_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_train, y_train_train, X_train_val, y_train_val, X_test\n",
    "\n",
    "\n",
    "def train_until_convergence(models, X, y, verbose=True):\n",
    "    time_start = time.time()\n",
    "    for i, model in enumerate(models):\n",
    "        print_bis(f\"TRAINING UNTIL CONVERGENCE : MODEL #{i+1}/{len(models)} [ETA: {get_eta_repr(time.time() - time_start, i, len(models))}\")\n",
    "        model.set_params(max_iter=-1)\n",
    "        model.fit(X, y)\n",
    "    return models\n",
    "        \n",
    "\n",
    "def svm_no_PCA_selector( ## A REFAIRE AVEC LA DEUXIEME SELECTION SUR UN AUTRE SET QUE LA CROSS VALIDATION\n",
    "    make_input_func,\n",
    "    scaler,\n",
    "    params_grid,\n",
    "    name,\n",
    "    comments=\"\",\n",
    "    select=3,\n",
    "    max_iter=1000,\n",
    "    seed=None):\n",
    "    \n",
    "    params_grid_bounded = [{k: v for k, v in pg.items()} for pg in params_grid]\n",
    "    for d in params_grid_bounded:\n",
    "        d[\"max_iter\"] = max_iter\n",
    "    \n",
    "    X_train_train, y_train_train, X_train_val, y_train_val, X_test = \\\n",
    "        get_inputs_svm(make_input_func, scaler, seed=seed)\n",
    "   \n",
    "\n",
    "    # Hyperparameters space exploration\n",
    "\n",
    "    # Training\n",
    "    print(\"-------- (PRE-)TRAINING --------\")\n",
    "    svm_models = train_on_grid(SVC, params_grid_bounded, X_train_train, y_train_train)\n",
    "\n",
    "    # Scoring\n",
    "    print_ter(\"-------- CROSS-VALIDATION --------\")\n",
    "    svm_scores = get_models_custom_scoring(svm_models, X_train_train, y_train_train, X_train_val, y_train_val)\n",
    "\n",
    "    # Pre-Selecting\n",
    "    print_ter(\"-------- SELECTION --------\")\n",
    "    sorted_models = sort_models(svm_models, params_grid_bounded, svm_scores, criterion=\"validation_score\")\n",
    "    candidates = sorted_models[-select:]\n",
    "    candidates = [model for model, params, score in candidates]\n",
    "    \n",
    "    # Train until convergence\n",
    "    print_ter(\"-------- TRAINING CANDIDATES UNTIL CONVERGENCE --------\")\n",
    "    candidates_at_cvg = train_until_convergence(candidates, X_train_train, y_train_train)\n",
    "    \n",
    "    print_ter(\"-------- FINDING THE BEST MODEL --------\")\n",
    "    scores_at_cvg = get_models_custom_scoring(\n",
    "        candidates_at_cvg, X_train_train, y_train_train, X_train_val, y_train_val)\n",
    "    candidates_params = [cdt.get_params() for cdt in candidates_at_cvg]\n",
    "    \n",
    "    best_svm, best_svm_params, best_svm_scores =\\\n",
    "        get_best_model(candidates_at_cvg, candidates_params, scores_at_cvg, criterion=\"validation_score\") \n",
    "    \n",
    "    write_model_to_leaderboard(best_svm,\n",
    "                               name,\n",
    "                               best_svm_scores[\"training_score\"],\n",
    "                               best_svm_scores[\"validation_score\"],\n",
    "                               comments=comments\n",
    "                              )\n",
    "    return best_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- (PRE-)TRAINING --------\n",
      "Training Model #1/22 [ETA: ?]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #2/22 [ETA: 41.23s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #3/22 [ETA: 33.73s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #4/22 [ETA: 31.24s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #5/22 [ETA: 30.77s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #6/22 [ETA: 28.58s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #7/22 [ETA: 28.24s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #8/22 [ETA: 26.88s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #9/22 [ETA: 25.1s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #10/22 [ETA: 23.26s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #11/22 [ETA: 21.43s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #12/22 [ETA: 19.89s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #13/22 [ETA: 17.89s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #14/22 [ETA: 16.22s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #15/22 [ETA: 14.47s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #16/22 [ETA: 12.56s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #17/22 [ETA: 10.8s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #18/22 [ETA: 9.01s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #19/22 [ETA: 7.19s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #20/22 [ETA: 5.42s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #21/22 [ETA: 3.63s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #22/22 [ETA: 1.81s]\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------- CROSS-VALIDATION --------\n",
      "Scoring Model #22/22 [ETA: 3.71s]\u001b[1KK\n",
      "-------- SELECTION --------\n",
      "\n",
      "-------- TRAINING CANDIDATES UNTIL CONVERGENCE --------\n",
      "TRAINING UNTIL CONVERGENCE : MODEL #1/5 [ETA: ?\u001b[1K\r"
     ]
    }
   ],
   "source": [
    "### SVM with only extreme values without PCA\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "CREATE_SVM_EXTREME = True\n",
    "\n",
    "# Create input arrays\n",
    "def make_input_svm_extreme(h5_file):\n",
    "    return make_input(h5_file, features=FEATURES, quantiles=TAIL_QUANTILES, dist_char=False, truncate_dist=False)\n",
    "\n",
    "svm_extreme_params_grid_rbf_and_sigmoid = ParameterGrid(\n",
    "    {\"kernel\": [\"rbf\", \"sigmoid\"],\n",
    "     \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "     \"gamma\": [\"auto\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "svm_extreme_params_grid_polynomial = ParameterGrid(\n",
    "    {\"kernel\": [\"poly\"],\n",
    "     \"C\": [0.1, 1, 10],\n",
    "     \"degree\": [1, 2, 3, 4] #if max_iter != -1\n",
    "    })\n",
    "\n",
    "svm_extreme_params_grid = list(svm_extreme_params_grid_rbf_and_sigmoid) + list(svm_extreme_params_grid_polynomial)\n",
    "\n",
    "if CREATE_SVM_EXTREME:\n",
    "   \n",
    "    svm_no_PCA_selector(\n",
    "        make_input_func=make_input_svm_extreme,\n",
    "        params_grid=svm_extreme_params_grid,\n",
    "        scaler=StandardScaler(),\n",
    "        name='svm_extreme_selected_100',\n",
    "        comments=\"tailing quantiles; no distribution chars; all features; no PCA; seed=101\",\n",
    "        select=5,\n",
    "        max_iter=100,\n",
    "        seed=101)\n",
    "    \n",
    "# best_svm_extreme = load_model('svm_extreme_no_PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### SVM with only extreme values without PCA\n",
    "CREATE_SVM_CENTRAL = True\n",
    "\n",
    "# Create input arrays\n",
    "def make_input_svm_central(h5_file):\n",
    "    return make_input(h5_file, features=FEATURES, quantiles=list(), dist_char=True, truncate_dist=True)\n",
    "\n",
    "svm_central_grid_1 = ParameterGrid(\n",
    "    {\"kernel\": [\"rbf\", \"sigmoid\"],\n",
    "     \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "     \"gamma\": [\"auto\", \"scale\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "svm_central_grid_2 = ParameterGrid(\n",
    "    {\"kernel\": [\"poly\"],\n",
    "     \"C\": [0.1, 1, 10],\n",
    "     \"degree\": [1, 2, 3, 4] #if max_iter != -1\n",
    "    })\n",
    "\n",
    "svm_central_grid = list(svm_central_grid_1) + list(svm_central_grid_2)\n",
    "\n",
    "if CREATE_SVM_CENTRAL:\n",
    "    best_svm_central = \\\n",
    "        svm_no_PCA_selector(\n",
    "            make_input_func=make_input_svm_central,\n",
    "            params_grid=svm_central_grid,\n",
    "            scaler=StandardScaler(),\n",
    "            name='svm_central_selected_100',\n",
    "            comments=\"no quantiles; dist chars with truncation; all features; no PCA; seed=101\",\n",
    "            select=5, \n",
    "            max_iter=100,\n",
    "            seed=101\n",
    "        )\n",
    "    \n",
    "# best_svm_central = load_model('svm_central_selected_100')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVM with only extreme values without PCA\n",
    "CREATE_SVM_GLOUTON = True\n",
    "\n",
    "# Create input arrays\n",
    "def make_input_svm_glouton(h5_file):\n",
    "    return make_input(h5_file, features=FEATURES, quantiles=TAIL_QUANTILES, dist_char=True, truncate_dist=True)\n",
    "\n",
    "svm_glouton_grid_1 = ParameterGrid(\n",
    "    {\"kernel\": [\"rbf\", \"sigmoid\"],\n",
    "     \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "     \"gamma\": [\"auto\", \"scale\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "svm_glouton_grid_2 = ParameterGrid(\n",
    "    {\"kernel\": [\"poly\"],\n",
    "     \"C\": [0.1, 1, 10],\n",
    "     \"degree\": [1, 2, 3, 4] #if max_iter != -1\n",
    "    })\n",
    "\n",
    "svm_glouton_grid = list(svm_glouton_grid_1) + list(svm_glouton_grid_2)\n",
    "\n",
    "if CREATE_SVM_GLOUTON:\n",
    "    best_svm_glouton = \\\n",
    "        svm_no_PCA_selector(\n",
    "            make_input_func=make_input_svm_glouton,\n",
    "            params_grid=svm_glouton_grid,\n",
    "            scaler=StandardScaler(),\n",
    "            name='svm_glouton_selected_100',\n",
    "            comments=\"tail quantiles; dist chars with truncation; all features; no PCA; seed=101\",\n",
    "            select=5, \n",
    "            max_iter=100,\n",
    "            seed=101\n",
    "        )\n",
    "    \n",
    "# best_svm_glouton = load_model('svm_glouton_selected_100')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature #0\u001b[1KK\r"
     ]
    }
   ],
   "source": [
    "# make input for SVM\n",
    "LOG_ENERGY_FEATURES = [feature for feature in FEATURES if feature.endswith(\"logE\") and \"eeg\" in feature]\n",
    "\n",
    "MODEL_FEATURES = [*LOG_ENERGY_FEATURES, \"pulse_max_freq\", \"pulse_max_logE\", \"speed_norm\", \"accel_norm\"]\n",
    "\n",
    "X_train = make_input(h5_train, features=SVM_FEATURES, quantiles=QUANTILES_TAIL_CAPTURE)\n",
    "X_test = make_input(h5_test, features=SVM_FEATURES, quantiles=QUANTILES_TAIL_CAPTURE)\n",
    "\n",
    "train_ids, validation_ids = split_train_validation_subject_ids(0.7, seed=101)\n",
    "X_train_train, y_train_train, X_train_val, y_train_val = split_train_validation(X_train, train_subjects_ids=train_ids)\n",
    "\n",
    "### PCA on log_energy features\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_logE = PCA(0.9)\n",
    "pca_logE.fit(X_train_train[:, :len(LOG_ENERGY_FEATURES)])\n",
    "\n",
    "def apply_pca(X, pca, copy=True):\n",
    "    if copy:\n",
    "        return apply_pca(X[:, :], pca, copy=False)\n",
    "    X_transformed = pca.transform(X[:, :len(LOG_ENERGY_FEATURES)])\n",
    "    X[:, len(LOG_ENERGY_FEATURES) - pca.n_components_ : len(LOG_ENERGY_FEATURES)] = X_transformed\n",
    "    X = X[:, len(LOG_ENERGY_FEATURES) - pca.n_components_ :]\n",
    "    return X\n",
    "\n",
    "X_train_train = apply_pca(X_train_train, pca_logE)\n",
    "X_train_val = apply_pca(X_train_val, pca_logE)\n",
    "X_test = apply_pca(X_test, pca_logE)\n",
    "\n",
    "### Rescaling\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "# already robust on not logE features because we take quantiles\n",
    "# --> StandardScaler \n",
    "\n",
    "z_scaler = StandardScaler()\n",
    "\n",
    "X_train_train = z_scaler.fit_transform(X_train_train)\n",
    "X_train_val = z_scaler.transform(X_train_val)\n",
    "X_test = z_scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVC Models\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_params_grid_rbf_and_sigmoid = ParameterGrid(\n",
    "    {\"kernel\": [\"rbf\", \"sigmoid\"],\n",
    "     \"C\": [0.1, 1, 10],\n",
    "     \"gamma\": [\"scale\", \"auto\"]\n",
    "    })\n",
    "\n",
    "svm_params_grid_poly = ParameterGrid(\n",
    "    {\"kernel\": [\"poly\"],\n",
    "     \"C\": [0.1, 1, 10],\n",
    "     \"degree\": [3, 10] #if max_iter != -1\n",
    "    })\n",
    " \n",
    "svm_params_grid = list(svm_params_grid_rbf_and_sigmoid) + list(svm_params_grid_poly)\n",
    "\n",
    "svm_models = train_on_grid(SVC, svm_params_grid, X_train_train, y_train_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Model #17/18 [ETA: 16.0s]\u001b[1KKK\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train_macro': 0.34906001481735155,\n",
       "  'train_micro': 0.5051310682192801,\n",
       "  'validation_macro': 0.2763904479917661,\n",
       "  'validation_micro': 0.4335997279374256},\n",
       " {'train_macro': 0.2614320675993827,\n",
       "  'train_micro': 0.369011538257032,\n",
       "  'validation_macro': 0.25364166732316773,\n",
       "  'validation_micro': 0.3479000170039109},\n",
       " {'train_macro': 0.34906001481735155,\n",
       "  'train_micro': 0.5051310682192801,\n",
       "  'validation_macro': 0.2763904479917661,\n",
       "  'validation_micro': 0.4335997279374256},\n",
       " {'train_macro': 0.2614320675993827,\n",
       "  'train_micro': 0.369011538257032,\n",
       "  'validation_macro': 0.25364166732316773,\n",
       "  'validation_micro': 0.3479000170039109},\n",
       " {'train_macro': 0.4425298480449335,\n",
       "  'train_micro': 0.5605891423406179,\n",
       "  'validation_macro': 0.3625099634566772,\n",
       "  'validation_micro': 0.4762795442951879},\n",
       " {'train_macro': 0.2701379314099138,\n",
       "  'train_micro': 0.352634657308449,\n",
       "  'validation_macro': 0.2471371194507579,\n",
       "  'validation_micro': 0.3239245026356062},\n",
       " {'train_macro': 0.4425298480449335,\n",
       "  'train_micro': 0.5605891423406179,\n",
       "  'validation_macro': 0.3625099634566772,\n",
       "  'validation_micro': 0.4762795442951879},\n",
       " {'train_macro': 0.2701379314099138,\n",
       "  'train_micro': 0.352634657308449,\n",
       "  'validation_macro': 0.2471371194507579,\n",
       "  'validation_micro': 0.3239245026356062},\n",
       " {'train_macro': 0.5804677025683329,\n",
       "  'train_micro': 0.6554474397830595,\n",
       "  'validation_macro': 0.43988329111958446,\n",
       "  'validation_micro': 0.5169188913450093},\n",
       " {'train_macro': 0.26610912090439426,\n",
       "  'train_micro': 0.32881373956505555,\n",
       "  'validation_macro': 0.2544309155178751,\n",
       "  'validation_micro': 0.31389219520489714},\n",
       " {'train_macro': 0.5804677025683329,\n",
       "  'train_micro': 0.6554474397830595,\n",
       "  'validation_macro': 0.43988329111958446,\n",
       "  'validation_micro': 0.5169188913450093},\n",
       " {'train_macro': 0.26610912090439426,\n",
       "  'train_micro': 0.32881373956505555,\n",
       "  'validation_macro': 0.2544309155178751,\n",
       "  'validation_micro': 0.31389219520489714},\n",
       " {'train_macro': 0.3102744686201169,\n",
       "  'train_micro': 0.47982134311692454,\n",
       "  'validation_macro': 0.2327523496164874,\n",
       "  'validation_micro': 0.42373745961571163},\n",
       " {'train_macro': 0.41343745072922006,\n",
       "  'train_micro': 0.5233689583665656,\n",
       "  'validation_macro': 0.2101554504624652,\n",
       "  'validation_micro': 0.4091140962421357},\n",
       " {'train_macro': 0.363033653057082,\n",
       "  'train_micro': 0.505237411602063,\n",
       "  'validation_macro': 0.2592401077761147,\n",
       "  'validation_micro': 0.4301989457575242},\n",
       " {'train_macro': 0.4743140832015283,\n",
       "  'train_micro': 0.5573988408571277,\n",
       "  'validation_macro': 0.22802604748807948,\n",
       "  'validation_micro': 0.4111545655500765},\n",
       " {'train_macro': 0.434813429878487,\n",
       "  'train_micro': 0.5451161801456904,\n",
       "  'validation_macro': 0.29331375382746516,\n",
       "  'validation_micro': 0.42373745961571163},\n",
       " {'train_macro': 0.5377520855415243,\n",
       "  'train_micro': 0.5945126814483969,\n",
       "  'validation_macro': 0.25912130946572165,\n",
       "  'validation_micro': 0.4191464036728448}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_scores = get_models_custom_scoring(svm_models, X_train_train, y_train_train, X_train_val, y_train_val)\n",
    "svm_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-c626ed281ed3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvm_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_svm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_svm_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_svm_scores\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mget_best_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_params_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"validation_macro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_svm_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "best_svm_model, best_svm_params, best_svm_scores = \\\n",
    "    get_best_model(svm_models, svm_params_grid, svm_scores, criterion=\"validation_weighted\")\n",
    "best_svm_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #48/48 [ETA: 4.11s]\u001b[1KK\r"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "random_forest_params = {\n",
    "    \"n_estimators\": [10, 30, 100, 150],\n",
    "    \"max_depth\": [3, 10, 30, 100],\n",
    "    \"min_samples_leaf\": [1, 10, 100]}\n",
    "\n",
    "random_forest_params_grid = list(ParameterGrid(random_forest_params))\n",
    "\n",
    "random_forest_models = train_on_grid(\n",
    "    RandomForestClassifier, \n",
    "    random_forest_params_grid,\n",
    "    X_train_train,\n",
    "    y_train_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Model #47/48 [ETA: 0.15s]\u001b[1K\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">params</th>\n",
       "      <th colspan=\"2\" halign=\"left\">scores</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>train_weighted</th>\n",
       "      <th>validation_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>0.643324</td>\n",
       "      <td>0.463518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.632910</td>\n",
       "      <td>0.463180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.645184</td>\n",
       "      <td>0.459087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.636848</td>\n",
       "      <td>0.458153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.642077</td>\n",
       "      <td>0.458108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.650043</td>\n",
       "      <td>0.455831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>0.644333</td>\n",
       "      <td>0.452113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.776089</td>\n",
       "      <td>0.451573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.625828</td>\n",
       "      <td>0.448405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.730110</td>\n",
       "      <td>0.448180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.605076</td>\n",
       "      <td>0.446696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.642172</td>\n",
       "      <td>0.446280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.777016</td>\n",
       "      <td>0.445642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.733018</td>\n",
       "      <td>0.445101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.773608</td>\n",
       "      <td>0.443539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>0.736907</td>\n",
       "      <td>0.442927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.861906</td>\n",
       "      <td>0.440397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.620544</td>\n",
       "      <td>0.439826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>0.627548</td>\n",
       "      <td>0.435553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.848140</td>\n",
       "      <td>0.431173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>0.866251</td>\n",
       "      <td>0.428421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.867118</td>\n",
       "      <td>0.428166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.715539</td>\n",
       "      <td>0.426722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.865487</td>\n",
       "      <td>0.426040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.771079</td>\n",
       "      <td>0.425536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>0.867630</td>\n",
       "      <td>0.425310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.421711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.421072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.419689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.861385</td>\n",
       "      <td>0.418482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.852121</td>\n",
       "      <td>0.417446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.417376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.993775</td>\n",
       "      <td>0.409579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.999362</td>\n",
       "      <td>0.407556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.999415</td>\n",
       "      <td>0.406882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.430079</td>\n",
       "      <td>0.398412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.426527</td>\n",
       "      <td>0.397599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.423867</td>\n",
       "      <td>0.396972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.423755</td>\n",
       "      <td>0.396174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.427860</td>\n",
       "      <td>0.396089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>0.424250</td>\n",
       "      <td>0.395990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.427091</td>\n",
       "      <td>0.395918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>0.428306</td>\n",
       "      <td>0.395441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.993130</td>\n",
       "      <td>0.394673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.422541</td>\n",
       "      <td>0.393717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.421754</td>\n",
       "      <td>0.391809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.415593</td>\n",
       "      <td>0.376588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.381092</td>\n",
       "      <td>0.347265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      params                                       scores                    \n",
       "   max_depth min_samples_leaf n_estimators train_weighted validation_weighted\n",
       "33        30              100           30       0.643324            0.463518\n",
       "44       100              100           10       0.632910            0.463180\n",
       "47       100              100          150       0.645184            0.459087\n",
       "32        30              100           10       0.636848            0.458153\n",
       "35        30              100          150       0.642077            0.458108\n",
       "46       100              100          100       0.650043            0.455831\n",
       "45       100              100           30       0.644333            0.452113\n",
       "13        10                1           30       0.776089            0.451573\n",
       "22        10              100          100       0.625828            0.448405\n",
       "18        10               10          100       0.730110            0.448180\n",
       "20        10              100           10       0.605076            0.446696\n",
       "34        30              100          100       0.642172            0.446280\n",
       "15        10                1          150       0.777016            0.445642\n",
       "17        10               10           30       0.733018            0.445101\n",
       "14        10                1          100       0.773608            0.443539\n",
       "19        10               10          150       0.736907            0.442927\n",
       "29        30               10           30       0.861906            0.440397\n",
       "23        10              100          150       0.620544            0.439826\n",
       "21        10              100           30       0.627548            0.435553\n",
       "40       100               10           10       0.848140            0.431173\n",
       "31        30               10          150       0.866251            0.428421\n",
       "30        30               10          100       0.867118            0.428166\n",
       "16        10               10           10       0.715539            0.426722\n",
       "42       100               10          100       0.865487            0.426040\n",
       "12        10                1           10       0.771079            0.425536\n",
       "43       100               10          150       0.867630            0.425310\n",
       "26        30                1          100       0.999947            0.421711\n",
       "38       100                1          100       1.000000            0.421072\n",
       "27        30                1          150       1.000000            0.419689\n",
       "41       100               10           30       0.861385            0.418482\n",
       "28        30               10           10       0.852121            0.417446\n",
       "39       100                1          150       1.000000            0.417376\n",
       "24        30                1           10       0.993775            0.409579\n",
       "37       100                1           30       0.999362            0.407556\n",
       "25        30                1           30       0.999415            0.406882\n",
       "5          3               10           30       0.430079            0.398412\n",
       "10         3              100          100       0.426527            0.397599\n",
       "8          3              100           10       0.423867            0.396972\n",
       "11         3              100          150       0.423755            0.396174\n",
       "6          3               10          100       0.427860            0.396089\n",
       "9          3              100           30       0.424250            0.395990\n",
       "3          3                1          150       0.427091            0.395918\n",
       "7          3               10          150       0.428306            0.395441\n",
       "36       100                1           10       0.993130            0.394673\n",
       "1          3                1           30       0.422541            0.393717\n",
       "2          3                1          100       0.421754            0.391809\n",
       "0          3                1           10       0.415593            0.376588\n",
       "4          3               10           10       0.381092            0.347265"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_scores = get_models_custom_scoring(\n",
    "    random_forest_models,\n",
    "    X_train_train,\n",
    "    y_train_train,\n",
    "    X_train_val,\n",
    "    y_train_val\n",
    ")\n",
    "                   \n",
    "random_forest_results = pd.concat([pd.DataFrame(random_forest_params_grid), pd.DataFrame(random_forest_scores)],\n",
    "                                  keys=['params', 'scores'],\n",
    "                                  axis=1)\n",
    "\n",
    "random_forest_results = random_forest_results.sort_values(\n",
    "    by=[('scores', 'validation_weighted')], \n",
    "    ascending=False\n",
    ")\n",
    "random_forest_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_forest_model, _, _ = get_best_model(random_forest_models, random_forest_params_grid, random_forest_scores)\n",
    "    \n",
    "random_forest_prediction = best_random_forest_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New submission file at submission_rf.csv\n"
     ]
    }
   ],
   "source": [
    "from kaggle_submit import submit_to_kaggle\n",
    "\n",
    "submit_to_kaggle(random_forest_prediction, h5_test, fname=\"submission_rf.csv\", msg=\"rf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_train.close()\n",
    "h5_test.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
