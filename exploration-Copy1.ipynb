{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "from kaggle_submit import submit_to_kaggle\n",
    "from helpers import *\n",
    "\n",
    "PICTURES_FOLDER = \"pictures\"\n",
    "os.makedirs(PICTURES_FOLDER, exist_ok=True)\n",
    "\n",
    "SLEEP_STAGES_COLORS = {\n",
    "    0: \"blue\",\n",
    "    1: \"green\",     \n",
    "    2: \"red\",\n",
    "    3: \"black\",\n",
    "    4: \"orange\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"kaggle_data/X_train.h5/X_train.h5\"\n",
    "test_file = \"kaggle_data/X_test.h5/X_test.h5\"\n",
    "\n",
    "h5_train = h5py.File(train_file, mode='a')\n",
    "h5_test = h5py.File(test_file, mode='a')\n",
    "\n",
    "y_train = pd.read_csv(\"kaggle_data/y_train.csv\", index_col=0, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES (sorted) = ['accel_norm', 'alpha_eeg_1_logE', 'alpha_eeg_2_logE', 'alpha_eeg_3_logE', 'alpha_eeg_4_logE', 'alpha_eeg_5_logE', 'alpha_eeg_6_logE', 'alpha_eeg_7_logE', 'beta_eeg_1_logE', 'beta_eeg_2_logE', 'beta_eeg_3_logE', 'beta_eeg_4_logE', 'beta_eeg_5_logE', 'beta_eeg_6_logE', 'beta_eeg_7_logE', 'delta_eeg_1_logE', 'delta_eeg_2_logE', 'delta_eeg_3_logE', 'delta_eeg_4_logE', 'delta_eeg_5_logE', 'delta_eeg_6_logE', 'delta_eeg_7_logE', 'eeg_1', 'eeg_2', 'eeg_3', 'eeg_4', 'eeg_5', 'eeg_6', 'eeg_7', 'pulse', 'speed_norm', 'theta_eeg_1_logE', 'theta_eeg_2_logE', 'theta_eeg_3_logE', 'theta_eeg_4_logE', 'theta_eeg_5_logE', 'theta_eeg_6_logE', 'theta_eeg_7_logE']\n"
     ]
    }
   ],
   "source": [
    "IRRELEVANT_FEATURES = ['index', 'index_absolute', 'index_window',\n",
    "                       'x', 'y', 'z',\n",
    "                       'speed_x', 'speed_y', 'speed_z']\n",
    "\n",
    "def update_globals():\n",
    "    features = [feat for feat in h5_train.keys() if feat not in IRRELEVANT_FEATURES]\n",
    "    frequencies = {feat: h5_train[feat][0].size // 30 for feat in features}\n",
    "    frequencies = {feat: freq if int(freq) in (10, 50) else 0 \n",
    "                   for feat, freq in frequencies.items()}\n",
    "    return features, frequencies\n",
    "    \n",
    "FEATURES, FREQUENCIES = update_globals()\n",
    "print(\"FEATURES (sorted) =\", sorted(FEATURES))\n",
    "# print(\"FREQUENCIES =\", FREQUENCIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# get_subject_feature_signals(h5_train, 1, \"eeg_1\", as_timeseries=False)\n",
    "# get_subject_feature_signals(h5_train, 1, \"eeg_1\", as_timeseries=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accel_norm', 'alpha_eeg_1_logE', 'alpha_eeg_2_logE', 'alpha_eeg_3_logE', 'alpha_eeg_4_logE', 'alpha_eeg_5_logE', 'alpha_eeg_6_logE', 'alpha_eeg_7_logE', 'beta_eeg_1_logE', 'beta_eeg_2_logE', 'beta_eeg_3_logE', 'beta_eeg_4_logE', 'beta_eeg_5_logE', 'beta_eeg_6_logE', 'beta_eeg_7_logE', 'delta_eeg_1_logE', 'delta_eeg_2_logE', 'delta_eeg_3_logE', 'delta_eeg_4_logE', 'delta_eeg_5_logE', 'delta_eeg_6_logE', 'delta_eeg_7_logE', 'eeg_1', 'eeg_2', 'eeg_3', 'eeg_4', 'eeg_5', 'eeg_6', 'eeg_7', 'pulse', 'speed_norm', 'theta_eeg_1_logE', 'theta_eeg_2_logE', 'theta_eeg_3_logE', 'theta_eeg_4_logE', 'theta_eeg_5_logE', 'theta_eeg_6_logE', 'theta_eeg_7_logE']\n"
     ]
    }
   ],
   "source": [
    "from speed_and_accel import _create_speed_and_acceleration\n",
    "\n",
    "# Create speed and acceleration\n",
    "_create_speed_and_acceleration(h5_train, overwrite=False, verbose=True)\n",
    "_create_speed_and_acceleration(h5_test, overwrite=False, verbose=True)\n",
    "FEATURES, FREQUENCIES = update_globals()\n",
    "print(FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Name     | Frequency (Hz)|\n",
    "| ---------| -----------|\n",
    "| $\\delta$ | 0-4 |\n",
    "| $\\theta$ | 4-8 |\n",
    "| $\\alpha$ | 8-13 |\n",
    "| $\\beta$  | 13-22 |\n",
    "| $\\gamma$ | 30-. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQUENCIES = {'accel_norm': 10, 'alpha_eeg_1_logE': 0, 'alpha_eeg_2_logE': 0, 'alpha_eeg_3_logE': 0, 'alpha_eeg_4_logE': 0, 'alpha_eeg_5_logE': 0, 'alpha_eeg_6_logE': 0, 'alpha_eeg_7_logE': 0, 'beta_eeg_1_logE': 0, 'beta_eeg_2_logE': 0, 'beta_eeg_3_logE': 0, 'beta_eeg_4_logE': 0, 'beta_eeg_5_logE': 0, 'beta_eeg_6_logE': 0, 'beta_eeg_7_logE': 0, 'delta_eeg_1_logE': 0, 'delta_eeg_2_logE': 0, 'delta_eeg_3_logE': 0, 'delta_eeg_4_logE': 0, 'delta_eeg_5_logE': 0, 'delta_eeg_6_logE': 0, 'delta_eeg_7_logE': 0, 'eeg_1': 50, 'eeg_2': 50, 'eeg_3': 50, 'eeg_4': 50, 'eeg_5': 50, 'eeg_6': 50, 'eeg_7': 50, 'pulse': 10, 'speed_norm': 10, 'theta_eeg_1_logE': 0, 'theta_eeg_2_logE': 0, 'theta_eeg_3_logE': 0, 'theta_eeg_4_logE': 0, 'theta_eeg_5_logE': 0, 'theta_eeg_6_logE': 0, 'theta_eeg_7_logE': 0}\n"
     ]
    }
   ],
   "source": [
    "from eeg_band_log_energies import _create_log_energy\n",
    "\n",
    "_create_log_energy(h5_train, n_chunks=100, overwrite=False, verbose=True)\n",
    "_create_log_energy(h5_test, n_chunks=100, overwrite=False, verbose=True)\n",
    "FEATURES, FREQUENCIES = update_globals()\n",
    "# print(\"FEATURES =\", FEATURES)\n",
    "print(\"FREQUENCIES =\", FREQUENCIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE #37 SUBJECT 31/31 (RESCALE = True)\u001b[1KK\r"
     ]
    }
   ],
   "source": [
    "def robust_rescale(df):\n",
    "    \"\"\"\n",
    "    X_rescaled = (X - MED(X)) / MED(|X - MED(X)|)\n",
    "    \"\"\"\n",
    "    med = df.median()\n",
    "    med_spread = (df - df.median()).abs().median()\n",
    "    # df_rescaled = (df - med) / med_spread\n",
    "    return (df - med) / med_spread\n",
    "\n",
    "def min_max_rescale(df):\n",
    "    min_ = df.min()\n",
    "    max_ = df.max()\n",
    "    return (df - min_) / (max_ - min_)\n",
    "    \n",
    "def z_rescale(df): \n",
    "    mean = df.mean()\n",
    "    std = df.std()\n",
    "    return (df - mean) / std\n",
    "\n",
    "def get_fig_subjects():\n",
    "    fig, axes = plt.subplots(10, 3, figsize=(10, 40))\n",
    "    return fig, np.ravel(axes)\n",
    "\n",
    "def title_with_subject_id(ax, subject_id):\n",
    "    ax.set_title(f'SUBJECT #{subject_id}')\n",
    "    return None\n",
    "\n",
    "def save_feature_quantiles(feature,\n",
    "                           inf_qt=0.025,\n",
    "                           sup_qt=0.975,\n",
    "                           n_quantiles=21,\n",
    "                           robust_rescaling=False,\n",
    "                           overwrite=False,\n",
    "                           verbose=True):\n",
    "    \"\"\"\n",
    "    See pictures/quantile_plots\n",
    "    \n",
    "    Can be improved (make robust and not robust qplots simultaneously)\n",
    "    \"\"\"\n",
    "    # Make directory if it does not exist\n",
    "    qplot_dir = os.path.join(PICTURES_FOLDER, f\"quantile_plots\")\n",
    "    os.makedirs(qplot_dir, exist_ok=True)\n",
    "    # Escape if not overwrite and already done\n",
    "    qplot_fname = os.path.join(qplot_dir, f'{feature}{\"--rescaled\" if robust_rescaling else \"\"}.png')\n",
    "    if (not overwrite) and os.path.exists(qplot_fname):\n",
    "        return None\n",
    "    # Otherwise,\n",
    "    subject_ids = get_subject_ids(h5_train)\n",
    "    quantiles = np.linspace(inf_qt, sup_qt, n_quantiles).round(3)\n",
    "    subjects_quantiles = dict()\n",
    "    for cnt, sid in enumerate(subject_ids):\n",
    "        if verbose:\n",
    "            print_bis(f\"FEATURE #{FEATURES.index(feature)} SUBJECT {cnt+1}/{len(subject_ids)} (RESCALE = {str(robust_rescaling)})\")\n",
    "        # Robust representation of the signal\n",
    "        signal = get_subject_feature_signals(h5_train, sid, feature, as_timeseries=False)\n",
    "        size = signal[0].size\n",
    "        signal = pd.Series(np.concatenate(signal))\n",
    "        if robust_rescaling:\n",
    "            signal = robust_rescale(signal)\n",
    "        # Behaviour by sleep stage\n",
    "        sleep_stages = get_subject_sleep_stage(sid, h5_train).values\n",
    "        signal_by_stage = signal.groupby(np.repeat(sleep_stages, size))\n",
    "        subjects_quantiles[sid] = signal_by_stage.quantile(quantiles).unstack(0)\n",
    "        \n",
    "    fig, axes = get_fig_subjects()\n",
    "    for ax, sid in zip(axes, subject_ids):\n",
    "        subjects_quantiles[sid].plot(ax=ax)#, color=SLEEP_STAGES_COLORS)\n",
    "        title_with_subject_id(ax, sid)\n",
    "    plt.savefig(qplot_fname)\n",
    "    plt.close(fig)\n",
    "    return subjects_quantiles\n",
    "\n",
    "\n",
    "# TO WRITE QUANTILE PLOTS IN pictures/quantile_plots\n",
    "for i, feat in enumerate(FEATURES):\n",
    "    # print_ter(f\"========= FEATURE {i+1}/{len(FEATURES)} =========\")\n",
    "    save_feature_quantiles(feat, robust_rescaling=False, overwrite=False, verbose=True)\n",
    "    save_feature_quantiles(feat, robust_rescaling=True, overwrite=False, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT #29\u001b[1K\r"
     ]
    }
   ],
   "source": [
    "def get_proba_transition(subject_id=None):\n",
    "    if subject_id:\n",
    "        start, end = get_subject_boundaries(h5_train, subject_id, ready_to_use=False)\n",
    "        y = y_train.loc[start:end]\n",
    "    else: # all subjects\n",
    "        y = y_train.loc[:]\n",
    "    transition_df = pd.DataFrame(data={\"stage\": y, \"stage_after\": y.shift(-1)})\n",
    "    transition_df = transition_df.iloc[:-1] # NaN\n",
    "    transition_df = transition_df.astype(int)\n",
    "    counts = transition_df.groupby([\"stage\", \"stage_after\"]).size()\n",
    "    counts = counts.unstack(1, fill_value=0)\n",
    "    probas = counts.div(counts.sum(axis=1), axis=0)\n",
    "    probas = probas.reindex(range(0, 5), axis=0, fill_value=0)\n",
    "    probas = probas.reindex(range(0, 5), axis=1, fill_value=0)\n",
    "    return probas\n",
    "\n",
    "transition_plots_dir = os.path.join(PICTURES_FOLDER, \"transition_plots\")\n",
    "os.makedirs(transition_plots_dir, exist_ok=True)\n",
    "\n",
    "def save_transition_plots_by_subject(overwrite=False, verbose=True):\n",
    "    fpath = os.path.join(transition_plots_dir, \"transition_matrix_by_subject.png\")\n",
    "    if (not overwrite) and os.path.exists(fpath):\n",
    "        return None\n",
    "    subject_ids = get_subject_ids(h5_train)\n",
    "    fig, axes = get_fig_subjects()\n",
    "    for ax, sid in zip(axes, subject_ids):\n",
    "        if verbose:\n",
    "            print_bis(f\"SUBJECT #{sid}\")\n",
    "        probas = get_proba_transition(subject_id=sid)\n",
    "        sns.heatmap(probas, ax=ax, vmin=0, vmax=1, annot=True)\n",
    "        title_with_subject_id(ax, sid)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(fpath)\n",
    "    plt.close(fig)    \n",
    "    return None\n",
    "\n",
    "def save_transition_plot_global(overwrite=False):\n",
    "    fpath = os.path.join(transition_plots_dir, \"transition_matrix_global.png\")\n",
    "    if (not overwrite) and os.path.exists(fpath):\n",
    "        return None\n",
    "    proba_global = get_proba_transition()\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(proba_global, ax=ax, vmin=0, vmax=1, annot=True)\n",
    "    fig.savefig(fpath)\n",
    "    plt.close(fig)\n",
    "    return None\n",
    "    \n",
    "save_transition_plots_by_subject(overwrite=False)\n",
    "save_transition_plot_global(overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd311fe1a20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_energies = [feature for feature, freq in FREQUENCIES.items() if freq == 0]\n",
    "log_energies_df = pd.DataFrame({le: h5_train[le][:][:, 0] for le in log_energies})\n",
    "sns.heatmap(log_energies_df.corr(), center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1     1671\n",
       "2    18898\n",
       "3    15672\n",
       "4    19332\n",
       "Name: sleep_stage, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_stages_frequencies = y_train.groupby(y_train.values).sum()\n",
    "sleep_stages_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moment(array,moments):\n",
    "    res = np.empty((array.shape[0],len(moments)))\n",
    "    for i in range(len(moments)):\n",
    "        res[:,i] = np.mean(np.power(array,moments[i]), axis=1)\n",
    "    return res\n",
    "\n",
    "def make_input_feature(h5_file, feature, quantiles, moments=[1,2,3,4], n_chunks=100):\n",
    "    print_bis(f\"Feature #{FEATURES.index(feature)}\")\n",
    "    if FREQUENCIES[feature] == 0:\n",
    "        return h5_file[feature][:]\n",
    "    feature_array = np.empty(shape=(h5_file[feature].shape[0], len(quantiles)+len(moments)))\n",
    "    for i, j in chunks_iterator(n_chunks, h5_file[feature].shape[0]):\n",
    "        feature_array[i:j, :] = np.concatenate((np.quantile(h5_file[feature][i:j], quantiles, axis=1).T,\n",
    "        moment(h5_file[feature][i:j],moments)),axis=1)\n",
    "    return feature_array\n",
    "\n",
    "def make_input(h5_file, features=None, quantiles=None):\n",
    "    if features is None:\n",
    "        features = FEATURES\n",
    "    if quantiles is None:\n",
    "        quantiles = QUANTILES\n",
    "    return np.concatenate([make_input_feature(h5_file, feat, quantiles) for feat in features], axis=1)\n",
    "    \n",
    "def split_train_validation_subject_ids(train_perc, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    subjects_ids = get_subject_ids(h5_train)\n",
    "    shuffled_ids = np.random.permutation(subjects_ids)\n",
    "    N_train = int(np.round(train_perc * len(shuffled_ids)))\n",
    "    train_ids, validation_ids = shuffled_ids[:N_train], shuffled_ids[N_train:]\n",
    "    return sorted(train_ids), sorted(validation_ids)\n",
    "\n",
    "def subjects_ids_to_indexers(h5_file, subjects_ids, as_indices=False, as_boolean_array=False):\n",
    "    if as_indices == as_boolean_array:\n",
    "        raise NameError('Choose between `indices` and `boolean array` representations')\n",
    "    if as_indices:\n",
    "        boundaries = [get_subject_boundaries(h5_file, sid, ready_to_use=False) for sid in subjects_ids]\n",
    "        return sum(map(lambda bounds: list(range(bounds[0], bounds[1]+1)), boundaries), list())\n",
    "    if as_boolean_array:\n",
    "        boolean_indexer = np.zeros(shape=(h5_file[FEATURES[0]].shape[0],), dtype=bool)\n",
    "        for sid in subjects_ids:\n",
    "            boolean_indexer[get_subject_boundaries(h5_file, sid, ready_to_use=True)] = True\n",
    "        return boolean_indexer\n",
    "        \n",
    "    \n",
    "def split_train_validation(X_train, \n",
    "                           train_subjects_ids=None, # ids for train\n",
    "                           train_perc=None,\n",
    "                           seed=None):\n",
    "    if (train_subjects_ids is None) and (train_perc is None):\n",
    "        raise NameError(\"Either `subjects_ids` or `train_perc` must be provided\")\n",
    "    if train_perc is not None:\n",
    "        train_subjects_ids, _ = split_train_validation_subject_ids(train_perc, seed)\n",
    "        return split_train_validation(X_train, train_subjects_ids=train_subjects_ids)\n",
    "    \n",
    "    train_selector = subjects_ids_to_indexers(h5_train, train_subjects_ids, as_boolean_array=True)\n",
    "    X_train_train, y_train_train = X_train[train_selector], y_train.values[train_selector]\n",
    "    X_train_val, y_train_val = X_train[~train_selector], y_train.values[~train_selector]\n",
    "    \n",
    "    return X_train_train, y_train_train, X_train_val, y_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.025000000000000005,\n",
       " 0.05286856317202822,\n",
       " 0.1118033988749895,\n",
       " 0.2364354022507939,\n",
       " 0.5,\n",
       " 0.763564597749206,\n",
       " 0.8881966011250105,\n",
       " 0.9471314368279717,\n",
       " 0.975]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUANTILES = [0.1, 0.5, 0.9]\n",
    "\n",
    "quantiles_first_half = np.logspace(np.log10(0.025), np.log10(0.5), num=5).tolist()\n",
    "QUANTILES_TAIL_CAPTURE = quantiles_first_half + [1 - q for q in quantiles_first_half[:-1]][::-1]\n",
    "QUANTILES_TAIL_CAPTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature #37\u001b[1K\r"
     ]
    }
   ],
   "source": [
    "X_train = make_input(h5_train, quantiles=QUANTILES_TAIL_CAPTURE)\n",
    "X_test = make_input(h5_test, quantiles=QUANTILES_TAIL_CAPTURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_train, y_train_train, X_train_val, y_train_val = split_train_validation(X_train, train_perc=0.7, seed=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def get_eta_repr(elapsed, iteration, total_iterations):\n",
    "    if iteration == 0:\n",
    "        return \"?\"\n",
    "    else:\n",
    "        eta = (elapsed / iteration) * (total_iterations - iteration)\n",
    "        return str(np.round(eta, 2)) + \"s\"\n",
    "    \n",
    "    \n",
    "def train_on_grid(model_blueprint, params_grid, X, y):\n",
    "    # Random shuffling of parameters for better ETA\n",
    "    shuffled_ix = np.random.permutation(range(len(params_grid))) # for better ETA\n",
    "    \n",
    "    models = [None for _ in range(len(params_grid))] \n",
    "    elapsed_time = 0\n",
    "    time_start = time.time()\n",
    "\n",
    "    for i, ix in enumerate(shuffled_ix):\n",
    "        print_bis(f\"Training Model #{i+1}/{len(params_grid)} \" +\\\n",
    "                  f\"[ETA: {get_eta_repr(time.time() - time_start, i, len(params_grid))}]\")\n",
    "        model = model_blueprint(**params_grid[ix])\n",
    "        model.fit(X, y)\n",
    "                \n",
    "        models[ix] = model\n",
    "        \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #48/48 [ETA: 8.98s]\u001b[1KKK\r"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "random_forest_params = {\n",
    "    \"n_estimators\": [10, 30, 100, 150],\n",
    "    \"max_depth\": [3, 10, 30, 100],\n",
    "    \"min_samples_leaf\": [1, 10, 100]}\n",
    "\n",
    "random_forest_params_grid = list(ParameterGrid(random_forest_params))\n",
    "\n",
    "random_forest_models = train_on_grid(\n",
    "    RandomForestClassifier, \n",
    "    random_forest_params_grid,\n",
    "    X_train_train,\n",
    "    y_train_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def custom_score(y_pred, y_true, average=\"weighted\"):\n",
    "    return fbeta_score(y_pred=y_pred,\n",
    "                       y_true=y_true,\n",
    "                       labels=[0, 1, 2, 3, 4],\n",
    "                       average=average,\n",
    "                       beta=1)\n",
    "\n",
    "def get_models_custom_scoring(models, X_train_train, y_train_train, X_train_val, y_train_val,\n",
    "                             averages=['macro', 'micro']):\n",
    "    scores = list()\n",
    "    time_start = time.time()\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        eta = get_eta_repr(time.time() - time_start, i, len(models))\n",
    "        print_bis(f\"Scoring Model #{i}/{len(models)} [ETA: {eta}]\")\n",
    "        \n",
    "        y_train_pred = model.predict(X_train_train)\n",
    "        y_val_pred = model.predict(X_train_val)\n",
    "        model_scores = {f\"train_{avg}\": custom_score(y_train_pred, y_train_train, average=avg) for avg in averages}\n",
    "        model_scores.update(\n",
    "            {f\"validation_{avg}\": custom_score(y_val_pred, y_train_val, average=avg) for avg in averages}\n",
    "        )\n",
    "        scores.append(model_scores)\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Model #47/48 [ETA: 0.22s]\u001b[1K\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">params</th>\n",
       "      <th colspan=\"2\" halign=\"left\">scores</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>train_weighted</th>\n",
       "      <th>validation_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.552679</td>\n",
       "      <td>0.496705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.544722</td>\n",
       "      <td>0.483202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.551735</td>\n",
       "      <td>0.495282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.549280</td>\n",
       "      <td>0.493638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.542282</td>\n",
       "      <td>0.493646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.547670</td>\n",
       "      <td>0.486330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.552421</td>\n",
       "      <td>0.494018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>0.551430</td>\n",
       "      <td>0.496462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.558854</td>\n",
       "      <td>0.511157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>0.545051</td>\n",
       "      <td>0.489332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.548959</td>\n",
       "      <td>0.493956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.549233</td>\n",
       "      <td>0.492418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.837560</td>\n",
       "      <td>0.602803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.845323</td>\n",
       "      <td>0.626475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.851301</td>\n",
       "      <td>0.620552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.852062</td>\n",
       "      <td>0.618302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.793958</td>\n",
       "      <td>0.603774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.802262</td>\n",
       "      <td>0.610840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.802682</td>\n",
       "      <td>0.618406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>0.804789</td>\n",
       "      <td>0.622965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.683094</td>\n",
       "      <td>0.593752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>0.689670</td>\n",
       "      <td>0.586294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.689041</td>\n",
       "      <td>0.603083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.691885</td>\n",
       "      <td>0.589233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.993773</td>\n",
       "      <td>0.590803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.621162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.624831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.629872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.859075</td>\n",
       "      <td>0.596769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.868453</td>\n",
       "      <td>0.625305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.873069</td>\n",
       "      <td>0.624476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>0.871916</td>\n",
       "      <td>0.630113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.692901</td>\n",
       "      <td>0.573217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>0.695408</td>\n",
       "      <td>0.588969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.695599</td>\n",
       "      <td>0.599129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.692748</td>\n",
       "      <td>0.598451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.993723</td>\n",
       "      <td>0.594511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.999468</td>\n",
       "      <td>0.625880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.633628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.633501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.855501</td>\n",
       "      <td>0.604016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.868218</td>\n",
       "      <td>0.625698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.872184</td>\n",
       "      <td>0.629160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>0.874153</td>\n",
       "      <td>0.621704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.685793</td>\n",
       "      <td>0.581229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>0.694668</td>\n",
       "      <td>0.586717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.694498</td>\n",
       "      <td>0.596327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.696810</td>\n",
       "      <td>0.601291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      params                                       scores                    \n",
       "   max_depth min_samples_leaf n_estimators train_weighted validation_weighted\n",
       "0          3                1           10       0.552679            0.496705\n",
       "1          3                1           30       0.544722            0.483202\n",
       "2          3                1          100       0.551735            0.495282\n",
       "3          3                1          150       0.549280            0.493638\n",
       "4          3               10           10       0.542282            0.493646\n",
       "5          3               10           30       0.547670            0.486330\n",
       "6          3               10          100       0.552421            0.494018\n",
       "7          3               10          150       0.551430            0.496462\n",
       "8          3              100           10       0.558854            0.511157\n",
       "9          3              100           30       0.545051            0.489332\n",
       "10         3              100          100       0.548959            0.493956\n",
       "11         3              100          150       0.549233            0.492418\n",
       "12        10                1           10       0.837560            0.602803\n",
       "13        10                1           30       0.845323            0.626475\n",
       "14        10                1          100       0.851301            0.620552\n",
       "15        10                1          150       0.852062            0.618302\n",
       "16        10               10           10       0.793958            0.603774\n",
       "17        10               10           30       0.802262            0.610840\n",
       "18        10               10          100       0.802682            0.618406\n",
       "19        10               10          150       0.804789            0.622965\n",
       "20        10              100           10       0.683094            0.593752\n",
       "21        10              100           30       0.689670            0.586294\n",
       "22        10              100          100       0.689041            0.603083\n",
       "23        10              100          150       0.691885            0.589233\n",
       "24        30                1           10       0.993773            0.590803\n",
       "25        30                1           30       0.999681            0.621162\n",
       "26        30                1          100       1.000000            0.624831\n",
       "27        30                1          150       0.999947            0.629872\n",
       "28        30               10           10       0.859075            0.596769\n",
       "29        30               10           30       0.868453            0.625305\n",
       "30        30               10          100       0.873069            0.624476\n",
       "31        30               10          150       0.871916            0.630113\n",
       "32        30              100           10       0.692901            0.573217\n",
       "33        30              100           30       0.695408            0.588969\n",
       "34        30              100          100       0.695599            0.599129\n",
       "35        30              100          150       0.692748            0.598451\n",
       "36       100                1           10       0.993723            0.594511\n",
       "37       100                1           30       0.999468            0.625880\n",
       "38       100                1          100       1.000000            0.633628\n",
       "39       100                1          150       1.000000            0.633501\n",
       "40       100               10           10       0.855501            0.604016\n",
       "41       100               10           30       0.868218            0.625698\n",
       "42       100               10          100       0.872184            0.629160\n",
       "43       100               10          150       0.874153            0.621704\n",
       "44       100              100           10       0.685793            0.581229\n",
       "45       100              100           30       0.694668            0.586717\n",
       "46       100              100          100       0.694498            0.596327\n",
       "47       100              100          150       0.696810            0.601291"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_scores = get_models_custom_scoring(\n",
    "    random_forest_models,\n",
    "    X_train_train,\n",
    "    y_train_train,\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    averages=['weighted']\n",
    ")\n",
    "                   \n",
    "random_forest_results = pd.concat([pd.DataFrame(random_forest_params_grid), pd.DataFrame(random_forest_scores)],\n",
    "                                  keys=['params', 'scores'],\n",
    "                                  axis=1)\n",
    "\n",
    "#random_forest_results = random_forest_results.sort_values(\n",
    "#    by=[('scores', 'validation_macro'), ('scores', 'validation_micro')], \n",
    "#    ascending=False\n",
    "#)\n",
    "random_forest_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_weighted': 1.0, 'validation_weighted': 0.6336284141892863}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_best_model(models, params_grid, scores, criterion=\"validation_weighted\"):\n",
    "    ix_best_score = np.argmax([s[criterion] for s in scores])\n",
    "    best_model = models[ix_best_score]\n",
    "    best_model_params = params_grid[ix_best_score]\n",
    "    best_model_score = scores[ix_best_score]\n",
    "    return best_model, best_model_params, best_model_score\n",
    "\n",
    "get_best_model(random_forest_models, random_forest_params_grid, random_forest_scores)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_forest_model, _, _ = get_best_model(random_forest_models, random_forest_params_grid, random_forest_scores)\n",
    "    \n",
    "prediction = best_random_forest_model.predict(X_test)\n",
    "#submission_file = save_for_submission(prediction)\n",
    "#send_submission_to_kaggle(submission_file, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model #18/18 [ETA: 27.43s]\u001b[1KK\r"
     ]
    }
   ],
   "source": [
    "# make input for SVM\n",
    "\n",
    "LOG_ENERGY_FEATURES = [feature for feature in FEATURES if feature.endswith(\"logE\")]\n",
    "SVM_FEATURES = [*LOG_ENERGY_FEATURES, \"pulse\", \"speed_norm\", \"accel_norm\"]\n",
    "\n",
    "X_train = make_input(h5_train, features=SVM_FEATURES, quantiles=QUANTILES_TAIL_CAPTURE)\n",
    "X_test = make_input(h5_test, features=SVM_FEATURES, quantiles=QUANTILES_TAIL_CAPTURE)\n",
    "\n",
    "train_ids, validation_ids = split_train_validation_subject_ids(0.7, seed=101)\n",
    "X_train_train, y_train_train, X_train_val, y_train_val = split_train_validation(X_train, train_subjects_ids=train_ids)\n",
    "\n",
    "### PCA on log_energy features\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_logE = PCA(0.9)\n",
    "pca_logE.fit(X_train_train[:, :len(LOG_ENERGY_FEATURES)])\n",
    "\n",
    "def apply_pca(X, pca, copy=True):\n",
    "    if copy:\n",
    "        return apply_pca(X[:, :], pca, copy=False)\n",
    "    X_transformed = pca.transform(X[:, :len(LOG_ENERGY_FEATURES)])\n",
    "    X[:, len(LOG_ENERGY_FEATURES) - pca.n_components_ : len(LOG_ENERGY_FEATURES)] = X_transformed\n",
    "    X = X[:, len(LOG_ENERGY_FEATURES) - pca.n_components_ :]\n",
    "    return X\n",
    "\n",
    "X_train_train = apply_pca(X_train_train, pca_logE)\n",
    "X_train_val = apply_pca(X_train_val, pca_logE)\n",
    "X_test = apply_pca(X_test, pca_logE)\n",
    "\n",
    "### Rescaling\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "# already robust on not logE features because we take quantiles\n",
    "# --> StandardScaler \n",
    "\n",
    "z_scaler = StandardScaler()\n",
    "\n",
    "X_train_train = z_scaler.fit_transform(X_train_train)\n",
    "X_train_val = z_scaler.transform(X_train_val)\n",
    "X_test = z_scaler.transform(X_test)\n",
    "\n",
    "### SVC Models\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_params_grid_rbf_and_sigmoid = ParameterGrid(\n",
    "    {\"kernel\": [\"rbf\", \"sigmoid\"],\n",
    "     \"C\": [0.1, 1, 10],\n",
    "     \"gamma\": [\"scale\", \"auto\"]\n",
    "    })\n",
    "\n",
    "svm_params_grid_poly = ParameterGrid(\n",
    "    {\"kernel\": [\"poly\"],\n",
    "     \"C\": [0.1, 1, 10],\n",
    "     \"degree\": [3, 10] #if max_iter != -1\n",
    "    })\n",
    " \n",
    "svm_params_grid = list(svm_params_grid_rbf_and_sigmoid) + list(svm_params_grid_poly)\n",
    "\n",
    "svm_models = train_on_grid(SVC, svm_params_grid, X_train_train, y_train_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Model #5/18 [ETA: 220.17s]\u001b[1K\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-c4d493d684ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvm_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_models_custom_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msvm_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-3487a370e00e>\u001b[0m in \u001b[0;36mget_models_custom_scoring\u001b[0;34m(models, X_train_train, y_train_train, X_train_val, y_train_val, averages)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint_bis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Scoring Model #{i}/{len(models)} [ETA: {eta}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0my_val_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmodel_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34mf\"train_{avg}\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcustom_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mavg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maverages\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0msvm_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLIBSVM_IMPL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         return libsvm.predict(\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_vectors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_support\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dual_coef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intercept_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svm_scores = get_models_custom_scoring(svm_models, X_train_train, y_train_train, X_train_val, y_train_val)\n",
    "svm_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_svm_model, best_svm_params, best_svm_scores = \\\n",
    "    get_best_model(svm_models, svm_params_grid, svm_scores, criterion=\"validation_macro\")\n",
    "best_svm_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_prediction = best_svm_model.predict(X_test)\n",
    "# svm_submission = save_for_submission(svm_prediction)\n",
    "# send_submission(svm_submission, \"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_train.close()\n",
    "h5_test.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
