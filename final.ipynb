{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "from kaggle_submit import submit_to_kaggle\n",
    "\n",
    "\n",
    "from objects import *\n",
    "from helpers import *\n",
    "# from utils.globals import *\n",
    "from utils.distribution_statistics import *\n",
    "\n",
    "train_file = \"kaggle_data/X_train.h5/X_train.h5\"\n",
    "test_file = \"kaggle_data/X_test.h5/X_test.h5\"\n",
    "\n",
    "def get_train_test_connections():\n",
    "    h5_train = h5py.File(train_file, mode='a')\n",
    "    h5_test = h5py.File(test_file, mode='a')\n",
    "    return h5_train, h5_test\n",
    "\n",
    "def close_train_test_connections(h5_train, h5_test):\n",
    "    h5_train.close()\n",
    "    h5_test.close()\n",
    "    \n",
    "#h5_train, h5_test = get_train_test_connections()\n",
    "\n",
    "y_train = pd.read_csv(\"kaggle_data/y_train.csv\", index_col=0, squeeze=True)\n",
    "y_train_arr = y_train.to_numpy()\n",
    "\n",
    "from utils.globals import *\n",
    "\n",
    "h5_train, h5_test = get_train_test_connections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import get_subject_ids\n",
    "\n",
    "train_ids = get_subject_ids(h5_train)\n",
    "np.random.seed(1)\n",
    "train_ids = np.random.permutation(train_ids)\n",
    "train_ids, validation_ids = train_ids[:28], train_ids[28:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.115 GB of training data: 3.092 s\n",
      "Binning 0.013 GB of validation data: 0.070 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/1000] 5 trees, 155 leaves (31 on avg), max depth = 9, train loss: 1.26780, val loss: 1.28141, in 1.370s\n",
      "[2/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 1.13080, val loss: 1.15616, in 1.362s\n",
      "[3/1000] 5 trees, 155 leaves (31 on avg), max depth = 9, train loss: 1.02543, val loss: 1.05826, in 1.437s\n",
      "[4/1000] 5 trees, 155 leaves (31 on avg), max depth = 9, train loss: 0.93966, val loss: 0.98096, in 2.375s\n",
      "[5/1000] 5 trees, 155 leaves (31 on avg), max depth = 9, train loss: 0.86914, val loss: 0.92067, in 1.259s\n",
      "[6/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.80959, val loss: 0.87099, in 1.030s\n",
      "[7/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.75788, val loss: 0.82642, in 1.246s\n",
      "[8/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.71364, val loss: 0.78840, in 2.075s\n",
      "[9/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.67433, val loss: 0.75468, in 1.658s\n",
      "[10/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.63946, val loss: 0.72693, in 1.029s\n",
      "[11/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.60823, val loss: 0.69969, in 1.074s\n",
      "[12/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.57978, val loss: 0.67798, in 1.947s\n",
      "[13/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.55416, val loss: 0.65791, in 1.989s\n",
      "[14/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.53042, val loss: 0.63922, in 1.229s\n",
      "[15/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.50910, val loss: 0.62191, in 1.328s\n",
      "[16/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.48920, val loss: 0.60709, in 2.362s\n",
      "[17/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.47126, val loss: 0.59372, in 1.503s\n",
      "[18/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.45296, val loss: 0.58013, in 1.101s\n",
      "[19/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.43624, val loss: 0.56715, in 1.090s\n",
      "[20/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.42083, val loss: 0.55622, in 2.053s\n",
      "[21/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.40681, val loss: 0.54718, in 1.727s\n",
      "[22/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.39356, val loss: 0.53874, in 1.039s\n",
      "[23/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.38104, val loss: 0.53126, in 1.079s\n",
      "[24/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.36939, val loss: 0.52321, in 2.058s\n",
      "[25/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.35791, val loss: 0.51644, in 1.706s\n",
      "[26/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.34694, val loss: 0.50883, in 1.062s\n",
      "[27/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.33648, val loss: 0.50208, in 1.149s\n",
      "[28/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.32666, val loss: 0.49632, in 2.358s\n",
      "[29/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.31702, val loss: 0.49087, in 1.966s\n",
      "[30/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.30768, val loss: 0.48600, in 1.067s\n",
      "[31/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.29960, val loss: 0.48280, in 1.177s\n",
      "[32/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.29144, val loss: 0.47796, in 2.102s\n",
      "[33/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.28373, val loss: 0.47380, in 1.840s\n",
      "[34/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.27614, val loss: 0.47044, in 1.099s\n",
      "[35/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.26933, val loss: 0.46737, in 1.192s\n",
      "[36/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.26192, val loss: 0.46277, in 1.874s\n",
      "[37/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.25505, val loss: 0.45965, in 2.048s\n",
      "[38/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.24864, val loss: 0.45643, in 1.085s\n",
      "[39/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.24203, val loss: 0.45350, in 1.087s\n",
      "[40/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.23617, val loss: 0.45037, in 2.064s\n",
      "[41/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.23044, val loss: 0.44743, in 1.702s\n",
      "[42/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.22448, val loss: 0.44427, in 1.085s\n",
      "[43/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.21875, val loss: 0.44082, in 1.336s\n",
      "[44/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.21304, val loss: 0.43779, in 2.575s\n",
      "[45/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.20784, val loss: 0.43526, in 1.976s\n",
      "[46/1000] 5 trees, 155 leaves (31 on avg), max depth = 16, train loss: 0.20266, val loss: 0.43371, in 1.058s\n",
      "[47/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.19750, val loss: 0.43049, in 1.189s\n",
      "[48/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.19300, val loss: 0.42920, in 2.053s\n",
      "[49/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.18836, val loss: 0.42740, in 2.062s\n",
      "[50/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.18389, val loss: 0.42488, in 1.085s\n",
      "[51/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.17960, val loss: 0.42396, in 1.088s\n",
      "[52/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.17566, val loss: 0.42225, in 2.302s\n",
      "[53/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.17139, val loss: 0.42067, in 2.127s\n",
      "[54/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.16745, val loss: 0.41966, in 1.047s\n",
      "[55/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.16365, val loss: 0.41823, in 1.125s\n",
      "[56/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.15983, val loss: 0.41724, in 2.164s\n",
      "[57/1000] 5 trees, 155 leaves (31 on avg), max depth = 16, train loss: 0.15622, val loss: 0.41578, in 1.716s\n",
      "[58/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.15270, val loss: 0.41384, in 1.025s\n",
      "[59/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.14924, val loss: 0.41243, in 1.807s\n",
      "[60/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.14600, val loss: 0.41151, in 2.117s\n",
      "[61/1000] 5 trees, 155 leaves (31 on avg), max depth = 16, train loss: 0.14256, val loss: 0.40970, in 1.675s\n",
      "[62/1000] 5 trees, 155 leaves (31 on avg), max depth = 19, train loss: 0.13937, val loss: 0.40804, in 1.060s\n",
      "[63/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.13643, val loss: 0.40712, in 1.102s\n",
      "[64/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.13326, val loss: 0.40522, in 3.013s\n",
      "[65/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.13045, val loss: 0.40401, in 1.009s\n",
      "[66/1000] 5 trees, 155 leaves (31 on avg), max depth = 19, train loss: 0.12782, val loss: 0.40332, in 0.978s\n",
      "[67/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.12511, val loss: 0.40313, in 1.056s\n",
      "[68/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.12237, val loss: 0.40184, in 3.284s\n",
      "[69/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.11988, val loss: 0.40139, in 2.854s\n",
      "[70/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.11737, val loss: 0.40121, in 2.113s\n",
      "[71/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.11504, val loss: 0.40035, in 1.720s\n",
      "[72/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.11251, val loss: 0.39971, in 3.086s\n",
      "[73/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.11016, val loss: 0.39831, in 1.982s\n",
      "[74/1000] 5 trees, 155 leaves (31 on avg), max depth = 16, train loss: 0.10787, val loss: 0.39728, in 1.071s\n",
      "[75/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.10564, val loss: 0.39652, in 1.045s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.10340, val loss: 0.39519, in 1.109s\n",
      "[77/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.10114, val loss: 0.39398, in 1.516s\n",
      "[78/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.09895, val loss: 0.39365, in 1.141s\n",
      "[79/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.09688, val loss: 0.39324, in 1.174s\n",
      "[80/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.09483, val loss: 0.39285, in 1.171s\n",
      "[81/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.09282, val loss: 0.39213, in 1.505s\n",
      "[82/1000] 5 trees, 155 leaves (31 on avg), max depth = 16, train loss: 0.09080, val loss: 0.39114, in 1.093s\n",
      "[83/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.08896, val loss: 0.39086, in 1.204s\n",
      "[84/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.08717, val loss: 0.38947, in 1.547s\n",
      "[85/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.08544, val loss: 0.38901, in 1.064s\n",
      "[86/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.08369, val loss: 0.38895, in 1.135s\n",
      "[87/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.08200, val loss: 0.38858, in 1.067s\n",
      "[88/1000] 5 trees, 155 leaves (31 on avg), max depth = 16, train loss: 0.08039, val loss: 0.38727, in 1.078s\n",
      "[89/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.07876, val loss: 0.38646, in 1.420s\n",
      "[90/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.07724, val loss: 0.38577, in 1.091s\n",
      "[91/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.07570, val loss: 0.38562, in 1.120s\n",
      "[92/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.07418, val loss: 0.38470, in 1.504s\n",
      "[93/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.07266, val loss: 0.38402, in 1.029s\n",
      "[94/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.07115, val loss: 0.38337, in 1.033s\n",
      "[95/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.06973, val loss: 0.38329, in 1.150s\n",
      "[96/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.06836, val loss: 0.38256, in 1.290s\n",
      "[97/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.06702, val loss: 0.38214, in 1.434s\n",
      "[98/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.06566, val loss: 0.38122, in 1.023s\n",
      "[99/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.06437, val loss: 0.38071, in 1.035s\n",
      "[100/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.06308, val loss: 0.38046, in 1.836s\n",
      "[101/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.06179, val loss: 0.37938, in 0.983s\n",
      "[102/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.06061, val loss: 0.37944, in 1.158s\n",
      "[103/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.05945, val loss: 0.37925, in 1.122s\n",
      "[104/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.05816, val loss: 0.37809, in 1.587s\n",
      "[105/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.05705, val loss: 0.37790, in 1.457s\n",
      "[106/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.05591, val loss: 0.37732, in 1.117s\n",
      "[107/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.05482, val loss: 0.37730, in 1.197s\n",
      "[108/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.05377, val loss: 0.37658, in 2.654s\n",
      "[109/1000] 5 trees, 155 leaves (31 on avg), max depth = 17, train loss: 0.05265, val loss: 0.37640, in 1.016s\n",
      "[110/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.05167, val loss: 0.37657, in 1.086s\n",
      "[111/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.05067, val loss: 0.37637, in 1.529s\n",
      "[112/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.04971, val loss: 0.37625, in 2.058s\n",
      "[113/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.04877, val loss: 0.37617, in 1.612s\n",
      "[114/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.04788, val loss: 0.37665, in 1.195s\n",
      "[115/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.04693, val loss: 0.37620, in 1.507s\n",
      "[116/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.04603, val loss: 0.37578, in 3.498s\n",
      "[117/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.04520, val loss: 0.37559, in 1.384s\n",
      "[118/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.04432, val loss: 0.37558, in 1.068s\n",
      "[119/1000] 5 trees, 155 leaves (31 on avg), max depth = 18, train loss: 0.04349, val loss: 0.37497, in 1.134s\n",
      "[120/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.04266, val loss: 0.37499, in 2.521s\n",
      "[121/1000] 5 trees, 155 leaves (31 on avg), max depth = 16, train loss: 0.04179, val loss: 0.37506, in 1.942s\n",
      "[122/1000] 5 trees, 155 leaves (31 on avg), max depth = 16, train loss: 0.04100, val loss: 0.37513, in 1.155s\n",
      "[123/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.04023, val loss: 0.37525, in 1.582s\n",
      "[124/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.03947, val loss: 0.37486, in 2.689s\n",
      "[125/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.03872, val loss: 0.37427, in 1.082s\n",
      "[126/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.03801, val loss: 0.37365, in 1.064s\n",
      "[127/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.03732, val loss: 0.37387, in 1.298s\n",
      "[128/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.03662, val loss: 0.37411, in 2.405s\n",
      "[129/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.03594, val loss: 0.37422, in 1.683s\n",
      "[130/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.03526, val loss: 0.37382, in 1.034s\n",
      "[131/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.03458, val loss: 0.37364, in 1.143s\n",
      "[132/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.03391, val loss: 0.37344, in 2.483s\n",
      "[133/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.03324, val loss: 0.37336, in 1.558s\n",
      "[134/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.03260, val loss: 0.37284, in 1.075s\n",
      "[135/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.03200, val loss: 0.37213, in 1.328s\n",
      "[136/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.03136, val loss: 0.37252, in 3.776s\n",
      "[137/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.03072, val loss: 0.37270, in 1.052s\n",
      "[138/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.03013, val loss: 0.37269, in 1.049s\n",
      "[139/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.02957, val loss: 0.37216, in 1.192s\n",
      "[140/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.02904, val loss: 0.37241, in 2.231s\n",
      "[141/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.02848, val loss: 0.37229, in 1.470s\n",
      "[142/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.02796, val loss: 0.37215, in 1.068s\n",
      "[143/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.02740, val loss: 0.37246, in 1.718s\n",
      "[144/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.02688, val loss: 0.37279, in 2.486s\n",
      "[145/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.02638, val loss: 0.37255, in 2.362s\n",
      "Fit 725 trees in 228.410 s, (22475 total leaves)\n",
      "Time spent computing histograms: 122.710s\n",
      "Time spent finding best splits:  54.517s\n",
      "Time spent applying splits:      28.323s\n",
      "Time spent predicting:           0.249s\n",
      "0.796072989711446\n"
     ]
    }
   ],
   "source": [
    "from final_models.best_hgb import BestHGB\n",
    "\n",
    "hgb = BestHGB(h5_train, h5_test, y_train_arr, train_ids)\n",
    "hgb.train()\n",
    "print(hgb.validation_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature #10/10\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:   13.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7499833379996307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:   29.0s finished\n",
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "from final_models.best_rf import BestRF\n",
    "\n",
    "rf = BestRF(h5_train, h5_test, y_train_arr, train_ids)\n",
    "rf.train()\n",
    "print(rf.validation_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score after vote (hard policy):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7642678599848916"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helpers import subjects_ids_to_indexers, custom_score\n",
    "\n",
    "y_validation_true = y_train_arr[subjects_ids_to_indexers(h5_train, subjects_ids=sorted(validation_ids), as_indices=True)]\n",
    "\n",
    "from final_models.vote import vote\n",
    "\n",
    "print(\"Validation score after vote (hard policy):\")\n",
    "y_validation_pred_hard = vote(models=[hgb, rf], weights=[0.5, 0.5], policy='hard', kind='validation')\n",
    "custom_score(y_validation_pred_hard, y_validation_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score after vote (soft policy):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7965753765487312"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from final_models.vote import vote\n",
    "print(\"Validation score after vote (soft policy):\")\n",
    "y_validation_pred_soft = vote(models=[hgb, rf], weights=[0.5, 0.9], policy='soft', kind='validation')\n",
    "custom_score(y_validation_pred_soft, y_validation_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "y_test = vote(models=[hgb, rf], weights=[0.5, 0.9], policy='soft', kind='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 1541 but corresponding boolean dimension is 811",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-87386476e40a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalidation_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubjects_ids_to_indexers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_boolean_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mexample_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubjects_ids_to_indexers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexample_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_boolean_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mexample_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_validation_pred_soft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample_ix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mexample_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_validation_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubjects_ids_to_indexers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexample_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 1541 but corresponding boolean dimension is 811"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "example_id = validation_ids[0]\n",
    "validation_ix = np.array(subjects_ids_to_indexers(h5_train, validation_ids, as_indices=True))\n",
    "example_ix = validation_ix[subjects_ids_to_indexers(h5_train, [example_id], as_boolean_array=True)]\n",
    "example_predicted = y_validation_pred_soft[example_ix]\n",
    "example_true = y_validation_true[subjects_ids_to_indexers(h5_train, [example_id], as_indices=True)]\n",
    "plt.plot(example_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 2, 2, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test.astype(int)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_submit import submit_to_kaggle\n",
    "\n",
    "#submit_to_kaggle(y_test, h5_test, fname=\"final_model.csv\", msg=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit",
   "language": "python",
   "name": "python37164bitdc6ddf9b5234459bacda0ad4bcef452b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
