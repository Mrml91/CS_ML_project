{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_create_band_signals\n",
      "_create_log_energy\n",
      "_create_log_modulus\n",
      "_create_pulse_max_log_energy_and_freq\n",
      "_create_speed_and_acceleration\n",
      "_create_time_features\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "from kaggle_submit import submit_to_kaggle\n",
    "\n",
    "\n",
    "from objects import *\n",
    "from helpers import *\n",
    "# from utils.globals import *\n",
    "from utils.distribution_statistics import *\n",
    "\n",
    "train_file = \"kaggle_data/X_train.h5/X_train.h5\"\n",
    "test_file = \"kaggle_data/X_test.h5/X_test.h5\"\n",
    "\n",
    "def get_train_test_connections():\n",
    "    h5_train = h5py.File(train_file, mode='a')\n",
    "    h5_test = h5py.File(test_file, mode='a')\n",
    "    return h5_train, h5_test\n",
    "\n",
    "def close_connections(*h5_conns):\n",
    "    for h5_file in h5_conns:\n",
    "        h5_file.close()\n",
    "    \n",
    "from additional_features.make_features import make_all_features\n",
    "h5_train, h5_test = get_train_test_connections()\n",
    "make_all_features(h5_train, h5_test, overwrite=False, verbose=True)\n",
    "close_connections(h5_train, h5_test)\n",
    "\n",
    "y_train = pd.read_csv(\"kaggle_data/y_train.csv\", index_col=0, squeeze=True)\n",
    "y_train_arr = y_train.to_numpy()\n",
    "\n",
    "from utils.globals import *\n",
    "\n",
    "h5_train, h5_test = get_train_test_connections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import get_subject_ids, subjects_ids_to_indexers\n",
    "\n",
    "train_ids = get_subject_ids(h5_train)\n",
    "np.random.seed(1)\n",
    "train_ids = np.random.permutation(train_ids)\n",
    "train_ids, validation_ids = train_ids[:28], train_ids[28:]\n",
    "\n",
    "validation_ix = subjects_ids_to_indexers(h5_train, validation_ids, as_boolean_array=True)\n",
    "y_validation_true = y_train_arr[validation_ix]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature #9/9\u001b[1K1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:   17.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature #28/28\u001b[1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:   23.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.115 GB of training data: 2.301 s\n",
      "Binning 0.013 GB of validation data: 0.063 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/1000] 5 trees, 155 leaves (31 on avg), max depth = 9, train loss: 1.26780, val loss: 1.28141, in 0.947s\n",
      "[2/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 1.13080, val loss: 1.15616, in 0.969s\n",
      "[3/1000] 5 trees, 155 leaves (31 on avg), max depth = 9, train loss: 1.02543, val loss: 1.05826, in 1.524s\n",
      "[4/1000] 5 trees, 155 leaves (31 on avg), max depth = 9, train loss: 0.93966, val loss: 0.98096, in 0.663s\n",
      "[5/1000] 5 trees, 155 leaves (31 on avg), max depth = 9, train loss: 0.86914, val loss: 0.92067, in 0.676s\n",
      "[6/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.80959, val loss: 0.87099, in 1.110s\n",
      "[7/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.75788, val loss: 0.82642, in 1.186s\n",
      "[8/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.71364, val loss: 0.78840, in 0.948s\n",
      "[9/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.67433, val loss: 0.75468, in 1.097s\n",
      "[10/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.63946, val loss: 0.72693, in 1.064s\n",
      "[11/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.60823, val loss: 0.69969, in 1.478s\n",
      "[12/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.57978, val loss: 0.67798, in 1.131s\n",
      "[13/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.55416, val loss: 0.65791, in 0.721s\n",
      "[14/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.53042, val loss: 0.63922, in 0.902s\n",
      "[15/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.50910, val loss: 0.62191, in 1.367s\n",
      "[16/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.48920, val loss: 0.60709, in 0.967s\n",
      "[17/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.47126, val loss: 0.59372, in 0.578s\n",
      "[18/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.45296, val loss: 0.58013, in 0.671s\n",
      "[19/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.43624, val loss: 0.56715, in 1.458s\n",
      "[20/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.42083, val loss: 0.55622, in 1.229s\n",
      "[21/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.40681, val loss: 0.54718, in 0.919s\n",
      "[22/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.39356, val loss: 0.53874, in 0.875s\n",
      "[23/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.38104, val loss: 0.53126, in 1.537s\n",
      "[24/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.36939, val loss: 0.52321, in 0.936s\n",
      "[25/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.35791, val loss: 0.51644, in 0.666s\n",
      "[26/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.34694, val loss: 0.50883, in 0.733s\n",
      "[27/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.33648, val loss: 0.50208, in 1.515s\n",
      "[28/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.32666, val loss: 0.49632, in 0.968s\n",
      "[29/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.31702, val loss: 0.49087, in 0.651s\n",
      "[30/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.30768, val loss: 0.48600, in 1.283s\n",
      "[31/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.29960, val loss: 0.48280, in 1.746s\n",
      "[32/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.29144, val loss: 0.47796, in 1.149s\n",
      "[33/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.28373, val loss: 0.47380, in 0.641s\n",
      "[34/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.27614, val loss: 0.47044, in 0.843s\n",
      "[35/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.26933, val loss: 0.46737, in 1.549s\n",
      "[36/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.26192, val loss: 0.46277, in 1.144s\n",
      "[37/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.25505, val loss: 0.45965, in 0.910s\n",
      "[38/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.24864, val loss: 0.45643, in 1.250s\n",
      "[39/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.24203, val loss: 0.45350, in 1.791s\n",
      "[40/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.23617, val loss: 0.45037, in 1.128s\n",
      "[41/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.23044, val loss: 0.44743, in 0.895s\n",
      "[42/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.22448, val loss: 0.44427, in 1.117s\n",
      "[43/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.21875, val loss: 0.44082, in 2.008s\n",
      "[44/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.21304, val loss: 0.43779, in 0.708s\n",
      "[45/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.20784, val loss: 0.43526, in 0.748s\n",
      "[46/1000] 5 trees, 155 leaves (31 on avg), max depth = 16, train loss: 0.20266, val loss: 0.43371, in 1.148s\n",
      "[47/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.19750, val loss: 0.43049, in 2.196s\n",
      "[48/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.19300, val loss: 0.42920, in 1.125s\n",
      "[49/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.18836, val loss: 0.42740, in 0.854s\n",
      "[50/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.18389, val loss: 0.42488, in 0.655s\n",
      "[51/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.17960, val loss: 0.42396, in 1.716s\n",
      "[52/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.17566, val loss: 0.42225, in 1.146s\n",
      "[53/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.17139, val loss: 0.42067, in 0.847s\n",
      "[54/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.16745, val loss: 0.41966, in 0.799s\n",
      "[55/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.16365, val loss: 0.41823, in 2.029s\n",
      "[56/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.15983, val loss: 0.41724, in 0.615s\n",
      "[57/1000] 5 trees, 155 leaves (31 on avg), max depth = 16, train loss: 0.15622, val loss: 0.41578, in 0.675s\n",
      "[58/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.15270, val loss: 0.41384, in 0.642s\n",
      "[59/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.14924, val loss: 0.41243, in 2.021s\n",
      "[60/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.14600, val loss: 0.41151, in 0.992s\n",
      "[61/1000] 5 trees, 155 leaves (31 on avg), max depth = 16, train loss: 0.14256, val loss: 0.40970, in 0.823s\n",
      "[62/1000] 5 trees, 155 leaves (31 on avg), max depth = 19, train loss: 0.13937, val loss: 0.40804, in 1.247s\n",
      "[63/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.13643, val loss: 0.40712, in 1.587s\n",
      "[64/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.13326, val loss: 0.40522, in 1.094s\n",
      "[65/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.13045, val loss: 0.40401, in 0.655s\n",
      "[66/1000] 5 trees, 155 leaves (31 on avg), max depth = 19, train loss: 0.12782, val loss: 0.40332, in 1.701s\n",
      "[67/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.12511, val loss: 0.40313, in 1.732s\n",
      "[68/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.12237, val loss: 0.40184, in 1.325s\n",
      "[69/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.11988, val loss: 0.40139, in 0.640s\n",
      "[70/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.11737, val loss: 0.40121, in 0.659s\n",
      "[71/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.11504, val loss: 0.40035, in 0.748s\n",
      "[72/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.11251, val loss: 0.39971, in 0.861s\n",
      "[73/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.11016, val loss: 0.39831, in 0.667s\n",
      "[74/1000] 5 trees, 155 leaves (31 on avg), max depth = 16, train loss: 0.10787, val loss: 0.39728, in 0.669s\n",
      "[75/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.10564, val loss: 0.39652, in 0.935s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.10340, val loss: 0.39519, in 0.663s\n",
      "[77/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.10114, val loss: 0.39398, in 0.691s\n",
      "[78/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.09895, val loss: 0.39365, in 0.663s\n",
      "[79/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.09688, val loss: 0.39324, in 0.852s\n",
      "[80/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.09483, val loss: 0.39285, in 0.705s\n",
      "[81/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.09282, val loss: 0.39213, in 0.662s\n",
      "[82/1000] 5 trees, 155 leaves (31 on avg), max depth = 16, train loss: 0.09080, val loss: 0.39114, in 0.785s\n",
      "[83/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.08896, val loss: 0.39086, in 0.711s\n",
      "[84/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.08717, val loss: 0.38947, in 1.345s\n",
      "[85/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.08544, val loss: 0.38901, in 0.669s\n",
      "[86/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.08369, val loss: 0.38895, in 0.635s\n",
      "[87/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.08200, val loss: 0.38858, in 0.992s\n",
      "[88/1000] 5 trees, 155 leaves (31 on avg), max depth = 16, train loss: 0.08039, val loss: 0.38727, in 0.569s\n",
      "[89/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.07876, val loss: 0.38646, in 0.589s\n",
      "[90/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.07724, val loss: 0.38577, in 0.629s\n",
      "[91/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.07570, val loss: 0.38562, in 0.657s\n",
      "[92/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.07418, val loss: 0.38470, in 0.807s\n",
      "[93/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.07266, val loss: 0.38402, in 0.576s\n",
      "[94/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.07115, val loss: 0.38337, in 0.581s\n",
      "[95/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.06973, val loss: 0.38329, in 0.830s\n",
      "[96/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.06836, val loss: 0.38256, in 0.558s\n",
      "[97/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.06702, val loss: 0.38214, in 0.626s\n",
      "[98/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.06566, val loss: 0.38122, in 0.777s\n",
      "[99/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.06437, val loss: 0.38071, in 1.794s\n",
      "[100/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.06308, val loss: 0.38046, in 1.221s\n",
      "[101/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.06179, val loss: 0.37938, in 0.753s\n",
      "[102/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.06061, val loss: 0.37944, in 0.679s\n",
      "[103/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.05945, val loss: 0.37925, in 1.801s\n",
      "[104/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.05816, val loss: 0.37809, in 0.787s\n",
      "[105/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.05705, val loss: 0.37790, in 0.795s\n",
      "[106/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.05591, val loss: 0.37732, in 0.899s\n",
      "[107/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.05482, val loss: 0.37730, in 1.583s\n",
      "[108/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.05377, val loss: 0.37658, in 1.141s\n",
      "[109/1000] 5 trees, 155 leaves (31 on avg), max depth = 17, train loss: 0.05265, val loss: 0.37640, in 0.738s\n",
      "[110/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.05167, val loss: 0.37657, in 0.705s\n",
      "[111/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.05067, val loss: 0.37637, in 1.630s\n",
      "[112/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.04971, val loss: 0.37625, in 1.016s\n",
      "[113/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.04877, val loss: 0.37617, in 0.578s\n",
      "[114/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.04788, val loss: 0.37665, in 0.612s\n",
      "[115/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.04693, val loss: 0.37620, in 1.878s\n",
      "[116/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.04603, val loss: 0.37578, in 0.582s\n",
      "[117/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.04520, val loss: 0.37559, in 0.602s\n",
      "[118/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.04432, val loss: 0.37558, in 0.702s\n",
      "[119/1000] 5 trees, 155 leaves (31 on avg), max depth = 18, train loss: 0.04349, val loss: 0.37497, in 1.759s\n",
      "[120/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.04266, val loss: 0.37499, in 0.870s\n",
      "[121/1000] 5 trees, 155 leaves (31 on avg), max depth = 16, train loss: 0.04179, val loss: 0.37506, in 0.592s\n",
      "[122/1000] 5 trees, 155 leaves (31 on avg), max depth = 16, train loss: 0.04100, val loss: 0.37513, in 0.948s\n",
      "[123/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.04023, val loss: 0.37525, in 1.895s\n",
      "[124/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.03947, val loss: 0.37486, in 0.992s\n",
      "[125/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.03872, val loss: 0.37427, in 0.596s\n",
      "[126/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.03801, val loss: 0.37365, in 0.814s\n",
      "[127/1000] 5 trees, 155 leaves (31 on avg), max depth = 15, train loss: 0.03732, val loss: 0.37387, in 1.803s\n",
      "[128/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.03662, val loss: 0.37411, in 0.932s\n",
      "[129/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.03594, val loss: 0.37422, in 0.607s\n",
      "[130/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.03526, val loss: 0.37382, in 1.007s\n",
      "[131/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.03458, val loss: 0.37364, in 2.021s\n",
      "[132/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.03391, val loss: 0.37344, in 0.582s\n",
      "[133/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.03324, val loss: 0.37336, in 0.608s\n",
      "[134/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.03260, val loss: 0.37284, in 0.831s\n",
      "[135/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.03200, val loss: 0.37213, in 1.753s\n",
      "[136/1000] 5 trees, 155 leaves (31 on avg), max depth = 10, train loss: 0.03136, val loss: 0.37252, in 0.951s\n",
      "[137/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.03072, val loss: 0.37270, in 0.614s\n",
      "[138/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.03013, val loss: 0.37269, in 0.996s\n",
      "[139/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.02957, val loss: 0.37216, in 1.979s\n",
      "[140/1000] 5 trees, 155 leaves (31 on avg), max depth = 11, train loss: 0.02904, val loss: 0.37241, in 1.217s\n",
      "[141/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.02848, val loss: 0.37229, in 0.565s\n",
      "[142/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.02796, val loss: 0.37215, in 0.591s\n",
      "[143/1000] 5 trees, 155 leaves (31 on avg), max depth = 12, train loss: 0.02740, val loss: 0.37246, in 0.614s\n",
      "[144/1000] 5 trees, 155 leaves (31 on avg), max depth = 13, train loss: 0.02688, val loss: 0.37279, in 0.849s\n",
      "[145/1000] 5 trees, 155 leaves (31 on avg), max depth = 14, train loss: 0.02638, val loss: 0.37255, in 0.582s\n",
      "Fit 725 trees in 148.789 s, (22475 total leaves)\n",
      "Time spent computing histograms: 80.155s\n",
      "Time spent finding best splits:  33.932s\n",
      "Time spent applying splits:      18.347s\n",
      "Time spent predicting:           0.130s\n",
      "Feature #9/9\u001b[1K1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature #9/9\u001b[1K1K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:  6.6min finished\n"
     ]
    }
   ],
   "source": [
    "from final_models.best_rf import BestRF\n",
    "from final_models.best_rf2 import BestRF2\n",
    "from final_models.best_hgb import BestHGB\n",
    "from final_models.classic_et import ClassicET\n",
    "from final_models.classic_bg import ClassicBG\n",
    "\n",
    "rf = BestRF(h5_train, h5_test, y_train_arr, train_ids)\n",
    "rf.train()\n",
    "# print(rf.validation_score)\n",
    "\n",
    "rf2 = BestRF2(h5_train, h5_test, y_train_arr, train_ids)\n",
    "rf2.train()\n",
    "# print(rf2.validation_score)\n",
    "\n",
    "hgb = BestHGB(h5_train, h5_test, y_train_arr, train_ids)\n",
    "hgb.train()\n",
    "# print(hgb.validation_score)\n",
    "\n",
    "et = ClassicET(h5_train, h5_test, y_train_arr, train_ids)\n",
    "et.train()\n",
    "# print(et.validation_score)\n",
    "\n",
    "bg = ClassicBG(h5_train, h5_test, y_train_arr, train_ids)\n",
    "bg.train()\n",
    "# print(bg.validation_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights : [4.903715297865709, 4.151362419976312, 3.5474887027100754, 3.684401471977287]\n",
      "soft : 0.7945263019564238\n",
      "hard : 0.7815097746360565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    3.4s finished\n"
     ]
    }
   ],
   "source": [
    "## ENSEMBLE LAST HARMONIC (not submitted)\n",
    "from final_models.vote import vote \n",
    "\n",
    "def get_harmonic_weight(model):\n",
    "    return 1 / (1 - model.validation_score)\n",
    "    \n",
    "models = [hgb, rf, et, bg]\n",
    "weights = [get_harmonic_weight(mod) for mod in [hgb, rf, et, bg]]\n",
    "\n",
    "y_validation_pred_soft = vote(\n",
    "        models=models, \n",
    "        weights=weights,\n",
    "        policy='soft',\n",
    "        kind='validation'\n",
    ")\n",
    "score_soft = custom_score(y_validation_pred_soft, y_validation_true)\n",
    "\n",
    "y_validation_pred_hard = vote(\n",
    "    models=models, \n",
    "    weights=weights, \n",
    "    policy='hard',\n",
    "    kind='validation'\n",
    ")\n",
    "score_hard = custom_score(y_validation_pred_hard, y_validation_true)\n",
    "\n",
    "y_test_pred_harmonic = vote(\n",
    "    models=models, \n",
    "    weights=weights, \n",
    "    policy='soft',\n",
    "    kind='test'\n",
    ")\n",
    "\n",
    "print(\"weights :\", weights)\n",
    "print('soft :', score_soft)\n",
    "print('hard :', score_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights : [1.9, 1.8, 1, 1]\n",
      "soft : 0.7945806234501889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    2.8s finished\n"
     ]
    }
   ],
   "source": [
    "## ENSEMBLE LAST (submitted)\n",
    "\n",
    "models = [hgb, rf, et, bg]\n",
    "weights = [1.9, 1.8, 1, 1]\n",
    "\n",
    "y_validation_pred_soft = vote(\n",
    "        models=models, \n",
    "        weights=weights,\n",
    "        policy='soft',\n",
    "        kind='validation'\n",
    ")\n",
    "score_soft = custom_score(y_validation_pred_soft, y_validation_true)\n",
    "\n",
    "y_test_pred_last = vote(\n",
    "    models=models, \n",
    "    weights=weights, \n",
    "    policy='soft',\n",
    "    kind='test'\n",
    ")\n",
    "\n",
    "\n",
    "#y_validation_pred_hard = vote(\n",
    "#    models=models, \n",
    "#    weights=weights, \n",
    "#    policy='hard',\n",
    "#    kind='validation'\n",
    "#)\n",
    "#score_hard = custom_score(y_validation_pred_hard, y_validation_true)\n",
    "\n",
    "print(\"weights :\", weights)\n",
    "print('soft :', score_soft)\n",
    "#print('hard :', score_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights : [0.5, 0.9]\n",
      "soft : 0.7820900556852667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "## FINAL MODEL (submitted)\n",
    "\n",
    "models = [hgb, rf2]\n",
    "weights = [0.5, 0.9]\n",
    "\n",
    "y_validation_pred_soft = vote(\n",
    "        models=models, \n",
    "        weights=weights,\n",
    "        policy='soft',\n",
    "        kind='validation'\n",
    ")\n",
    "score_soft = custom_score(y_validation_pred_soft, y_validation_true)\n",
    "\n",
    "#y_validation_pred_hard = vote(\n",
    "#    models=models, \n",
    "#    weights=weights, \n",
    "#    policy='hard',\n",
    "#    kind='validation'\n",
    "#)\n",
    "score_hard = custom_score(y_validation_pred_hard, y_validation_true)\n",
    "\n",
    "y_test_pred_final = vote(\n",
    "    models=models, \n",
    "    weights=weights, \n",
    "    policy='soft',\n",
    "    kind='test'\n",
    ")\n",
    "\n",
    "print(\"weights :\", weights)\n",
    "print('soft :', score_soft)\n",
    "#print('hard :', score_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from kaggle_submit import submit_to_kaggle # needs a set up of the kaggle API\n",
    "#submit_to_kaggle(y_test_pred_final, h5_test, fname='submission_final.csv', msg='')\n",
    "#submit_to_kaggle(y_test_pred_last, h5_test, fname='submission_last.csv', msg='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit",
   "language": "python",
   "name": "python37164bitdc6ddf9b5234459bacda0ad4bcef452b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
